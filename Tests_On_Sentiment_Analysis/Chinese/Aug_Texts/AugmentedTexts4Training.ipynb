{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b2de580",
   "metadata": {},
   "source": [
    "## Text sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93136c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample, seed\n",
    "from utils import load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6716c882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = load_dataset('../data/train.tsv')\n",
    "seed(175)\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8cc6174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_sampling(out_num):\n",
    "    return [t for t in sample(train, out_num)]\n",
    "\n",
    "\n",
    "def saveTextFile(data, filepath):\n",
    "    f = open(filepath, 'w')\n",
    "    tmp = \"\\n{}\\t{}\"\n",
    "    f.write(\"label\\ttext\")\n",
    "    for example in data:\n",
    "        f.write(tmp.format(str(example[1]), example[0]))\n",
    "    f.close()\n",
    "    print(filepath + \" has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf33c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "five_h = text_sampling(500)\n",
    "one_k = text_sampling(1000)\n",
    "three_k = text_sampling(3000)\n",
    "six_k = text_sampling(6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7f3cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/aug_texts/train_0.5k.txt has been saved!\n",
      "../data/aug_texts/train_1k.txt has been saved!\n",
      "../data/aug_texts/train_3k.txt has been saved!\n",
      "../data/aug_texts/train_5k.txt has been saved!\n",
      "../data/aug_texts/train_full.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "saveTextFile(five_h, '../data/aug_texts/train_0.5k.txt')\n",
    "saveTextFile(one_k, '../data/aug_texts/train_1k.txt')\n",
    "saveTextFile(three_k, '../data/aug_texts/train_3k.txt')\n",
    "saveTextFile(six_k, '../data/aug_texts/train_5k.txt')\n",
    "saveTextFile(train, '../data/aug_texts/train_full.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f462e",
   "metadata": {},
   "source": [
    "## Text Augmentation\n",
    "\n",
    "For every text pair, we will augment both texts and do cross pairing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7937d055",
   "metadata": {},
   "source": [
    "### DA models combined\n",
    "\n",
    "This is for two reasons: (1) efficiency; (2) more controlled, making sure that the augmented texts are sampled from the same pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "439301db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngramLM import NgramLM\n",
    "from reda import REDA\n",
    "from itertools import groupby\n",
    "from random import sample\n",
    "\n",
    "\n",
    "lm = NgramLM()\n",
    "\n",
    "\n",
    "class AugTextsWithTwoModels(REDA):\n",
    "    \n",
    "    def __int__(self, syn_path=None):\n",
    "        super.__init__(syn_path)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _out_num(edit_num, choice_num=None):\n",
    "        if choice_num:\n",
    "            return choice_num\n",
    "        if edit_num == 1:\n",
    "            return 20\n",
    "        if edit_num == 2:\n",
    "            return 50\n",
    "        if edit_num == 3:\n",
    "            return 100\n",
    "        return 150\n",
    "    \n",
    "    @staticmethod\n",
    "    def deduplicate(ori, lst):\n",
    "        lst.append(ori)\n",
    "        lst.sort()\n",
    "        lst = [l for l,_ in groupby(lst)]\n",
    "        lst.remove(ori)\n",
    "        return lst\n",
    "    \n",
    "    def augment(self, text, replace_rate=0.2, swap_rate=0.2, \n",
    "                insert_rate=0.1, delete_rate=0.1, max_mix=None, \n",
    "                out_num_each=2, out_str=True):\n",
    "        \n",
    "        def _filter(item):\n",
    "            '''A func to make sure that the data structure is all right as some operation might fail to augment \n",
    "            the text (e.g., too short, no synonyms etc.)'''\n",
    "            if isinstance(item, str):\n",
    "                return []\n",
    "            if not out_str and isinstance(item[0], str):\n",
    "                if len(item) == len(words):\n",
    "                    for i in range(words_num):\n",
    "                        if item[i] == words[i]:\n",
    "                            return []\n",
    "                return [item]\n",
    "            return item\n",
    "        \n",
    "        if isinstance(text, str):\n",
    "            words = self.tokenize(text)\n",
    "        elif isinstance(text, list):\n",
    "            words = text\n",
    "        else:\n",
    "            raise TypeError(\"The input text must be either a str or a list\")\n",
    "            \n",
    "        words_num = len(words)\n",
    "        replace_num = round(replace_rate * words_num) \n",
    "        swap_num = round(swap_rate * words_num) \n",
    "        insert_num = round(insert_rate * words_num) \n",
    "        delete_num = round(delete_rate * words_num) \n",
    "        \n",
    "        reda_out = []\n",
    "        ngram_out = []\n",
    "        _sample = lambda lst, num: sample(lst, num) if len(lst) >= num else sample(lst, len(lst))\n",
    "        out_num_each_special = out_num_each - 1 if out_num_each > 1 else out_num_each\n",
    "        \n",
    "        if replace_num:\n",
    "            out = _filter(self.replace_syn(words, replace_num, self._out_num(replace_num)))\n",
    "            reda_out.extend(_sample(out, out_num_each))\n",
    "            ngram_out.extend(lm.pickBestSent(out, out_num=out_num_each, out_str=out_str))\n",
    "        if swap_num:\n",
    "            out = _filter(self.swap_words(words, swap_num, self._out_num(swap_num)))\n",
    "            reda_out.extend(_sample(out, out_num_each))\n",
    "            ngram_out.extend(lm.pickBestSent(out, out_num=out_num_each, out_str=out_str))\n",
    "        if insert_num:\n",
    "            out = _filter(self.insert_words(words, insert_num, self._out_num(insert_num)))\n",
    "            reda_out.extend(_sample(out, out_num_each_special))\n",
    "            ngram_out.extend(lm.pickBestSent(out, out_num=out_num_each_special, out_str=out_str))\n",
    "        if delete_num:\n",
    "            out = _filter(self.delete_words(words, delete_num, self._out_num(delete_num)))\n",
    "            reda_out.extend(_sample(out, out_num_each_special))\n",
    "            ngram_out.extend(lm.pickBestSent(out, out_num=out_num_each_special, out_str=out_str))\n",
    "            \n",
    "        out = _filter(self.mixed_edits(words, 2, 50, out_str))\n",
    "        reda_out.extend(_sample(out, out_num_each_special))\n",
    "        ngram_out.extend(lm.pickBestSent(out, out_num=out_num_each_special, out_str=out_str))\n",
    "        \n",
    "        if out_str:\n",
    "            reda_out = [''.join(sent) for sent in reda_out]\n",
    "        # to deduplicate the outputs and ensure that the original text is no returned.\n",
    "        words = self._out_str(words, out_str)\n",
    "        \n",
    "        reda_out = self.deduplicate(words, reda_out)\n",
    "        ngram_out = self.deduplicate(words, ngram_out)\n",
    "        return reda_out, ngram_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5fd7739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textAugmentation(data, augModel, aug_num_each=2):\n",
    "    def augment(text, label):\n",
    "        out_reda = [(text, label)]\n",
    "        out_ngram = [(text, label)]\n",
    "        \n",
    "        aug_reda, aug_ngram = augModel.augment(text, out_num_each=aug_num_each)\n",
    "        out_reda.extend([(t, label) for t in aug_reda])\n",
    "        out_ngram.extend([(t, label) for t in aug_ngram])\n",
    "        \n",
    "        return out_reda, out_ngram\n",
    "    \n",
    "    if not isinstance(data[0], (tuple, list,)):\n",
    "        out_reda, out_ngram = augment(data[0], data[1], data[-1])\n",
    "        print('Texts augmented.')\n",
    "        print(f' Before (reda): 1. Now: {len(out_reda)}')\n",
    "        print(f' Before (ngram): 1. Now: {len(out_ngram)}')\n",
    "        return out_reda, out_ngram\n",
    "    \n",
    "    outputs_reda, outputs_gram = [], []\n",
    "    for example in tqdm(data):\n",
    "        out_reda, out_ngram = augment(example[0], example[1])\n",
    "        outputs_reda.extend(out_reda)\n",
    "        outputs_gram.extend(out_ngram)\n",
    "    print('Texts augmented.')\n",
    "    print(f'Before (reda): {len(data)}. Now: {len(outputs_reda)}')\n",
    "    print(f'Before (ngram): {len(data)}. Now: {len(outputs_gram)}')\n",
    "    return outputs_reda, outputs_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "197b5ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = AugTextsWithTwoModels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb0054c",
   "metadata": {},
   "source": [
    "### 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9d0afb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/500 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/w9/d_nplhzj4qx35xxlgljgdtjh0000gn/T/jieba.cache\n",
      "Loading model cost 0.685 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "100%|█████████████████████████████████████████| 500/500 [03:03<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 500. Now: 3997\n",
      "Before (ngram): 500. Now: 3991\n",
      "../data/aug_texts/train_0.5k_aug_reda.txt has been saved!\n",
      "../data/aug_texts/train_0.5_k_aug_reda_ngram.txt has been saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "five_h_aug_reda, five_h_aug_reda_ngram = textAugmentation(five_h, aug)\n",
    "saveTextFile(five_h_aug_reda, '../data/aug_texts/train_0.5k_aug_reda.txt')\n",
    "saveTextFile(five_h_aug_reda_ngram, '../data/aug_texts/train_0.5_k_aug_reda_ngram.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9905bc23",
   "metadata": {},
   "source": [
    "### 1,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3b79957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [05:47<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 1000. Now: 7992\n",
      "Before (ngram): 1000. Now: 7980\n",
      "../data/aug_texts/train_1k_aug_reda.txt has been saved!\n",
      "../data/aug_texts/train_1k_aug_reda_ngram.txt has been saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "one_k_aug_reda, one_k_aug_reda_ngram = textAugmentation(one_k, aug)\n",
    "saveTextFile(one_k_aug_reda, '../data/aug_texts/train_1k_aug_reda.txt')\n",
    "saveTextFile(one_k_aug_reda_ngram, '../data/aug_texts/train_1k_aug_reda_ngram.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f9cef",
   "metadata": {},
   "source": [
    "### 3,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e391d7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3000/3000 [16:47<00:00,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 3000. Now: 23991\n",
      "Before (ngram): 3000. Now: 23970\n",
      "../data/aug_texts/train_3k_aug_reda.txt has been saved!\n",
      "../data/aug_texts/train_3k_aug_reda_ngram.txt has been saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "three_k_aug_reda, three_k_aug_reda_ngram = textAugmentation(three_k, aug)\n",
    "saveTextFile(three_k_aug_reda, '../data/aug_texts/train_3k_aug_reda.txt')\n",
    "saveTextFile(three_k_aug_reda_ngram, '../data/aug_texts/train_3k_aug_reda_ngram.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6985e07e",
   "metadata": {},
   "source": [
    "### 6,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77e52fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 6000/6000 [33:19<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 6000. Now: 47994\n",
      "Before (ngram): 6000. Now: 47953\n",
      "../data/aug_texts/train_6k_aug_reda.txt has been saved!\n",
      "../data/aug_texts/train_6k_aug_reda_ngram.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "six_k_aug_reda, six_k_aug_reda_ngram = textAugmentation(six_k, aug)\n",
    "saveTextFile(six_k_aug_reda, '../data/aug_texts/train_6k_aug_reda.txt')\n",
    "saveTextFile(six_k_aug_reda_ngram, '../data/aug_texts/train_6k_aug_reda_ngram.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1cd812",
   "metadata": {},
   "source": [
    "### Full\n",
    "\n",
    "The two augmented train sets for the entire train set were gotten from another running window. The statistics for them are reported below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0f53218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 9600/9600 [53:08<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 9600. Now: 57576\n",
      "Before (ngram): 9600. Now: 57520\n",
      "../data/aug_texts/train_full_aug_reda.txt has been saved!\n",
      "../data/aug_texts/train_full_aug_reda_ngram.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "full_aug_reda, full_aug_reda_ngram = textAugmentation(train, aug, aug_num_each=1)\n",
    "saveTextFile(full_aug_reda, '../data/aug_texts/train_full_aug_reda.txt')\n",
    "saveTextFile(full_aug_reda_ngram, '../data/aug_texts/train_full_aug_reda_ngram.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
