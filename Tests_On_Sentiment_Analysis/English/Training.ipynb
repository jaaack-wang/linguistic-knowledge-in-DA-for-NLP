{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-02-11T19:31:29.947480Z",
     "iopub.status.busy": "2022-02-11T19:31:29.946913Z",
     "iopub.status.idle": "2022-02-11T19:31:37.247670Z",
     "shell.execute_reply": "2022-02-11T19:31:37.246922Z",
     "shell.execute_reply.started": "2022-02-11T19:31:29.947437Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two vocabulary dictionaries have been built!\n",
      "Please call X.vocab_to_idx | X.idx_to_vocab to find out more where [X] stands for the name you used for this TextVectorizer class.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "train = load_dataset('all_data/train_full.txt')\n",
    "texts = gather_text(train)\n",
    "V = TextVectorizer()\n",
    "V.build_vocab(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-02-11T19:31:37.400686Z",
     "iopub.status.busy": "2022-02-11T19:31:37.400417Z",
     "iopub.status.idle": "2022-02-11T19:31:37.409991Z",
     "shell.execute_reply": "2022-02-11T19:31:37.409222Z",
     "shell.execute_reply.started": "2022-02-11T19:31:37.400661Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model(model):\n",
    "    model = paddle.Model(model)\n",
    "    optimizer = paddle.optimizer.Adam(\n",
    "    parameters=model.parameters(), learning_rate=5e-4)\n",
    "    criterion = paddle.nn.CrossEntropyLoss()\n",
    "    metric = paddle.metric.Accuracy()\n",
    "    model.prepare(optimizer, criterion, metric)\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(model, data_loader):\n",
    "    labels, predictions = [], []\n",
    "    logits = model.predict(data_loader)\n",
    "    for batch in data_loader:\n",
    "        labels.extend(batch[-1].tolist())\n",
    "        \n",
    "    for batch in logits[0]:\n",
    "        batch = paddle.to_tensor(batch)\n",
    "        probs = F.softmax(batch, axis=1)\n",
    "        preds = paddle.argmax(probs, axis=1).numpy().tolist()\n",
    "        predictions.extend(preds)\n",
    "        \n",
    "    return predictions, labels\n",
    "\n",
    "\n",
    "def get_accu_pre_recall_f1(preds, labels): \n",
    "    \n",
    "    tp, fp, tn, fn, right = 0, 0, 0, 0, 0\n",
    "    \n",
    "    for (i, j) in zip(preds, labels):\n",
    "        if i == 1 and j == 1:\n",
    "            tp += 1\n",
    "            right += 1\n",
    "        elif i == 1 and j == 0:\n",
    "            fp += 1\n",
    "        elif i == 0 and j == 0:\n",
    "            tn += 1\n",
    "            right += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    \n",
    "    A = round(right/len(preds), 3)\n",
    "    try:\n",
    "        P = round(tp / (tp + fp), 3)\n",
    "    except:\n",
    "        return [A, 'Nan', 'Nan', 'Nan']\n",
    "    R = round(tp / (tp + fn), 3)\n",
    "    F1 = round(2 * P * R / (P + R), 3)\n",
    "    \n",
    "    return [A, P, R, F1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-02-11T19:31:37.411149Z",
     "iopub.status.busy": "2022-02-11T19:31:37.410988Z",
     "iopub.status.idle": "2022-02-11T19:31:37.422455Z",
     "shell.execute_reply": "2022-02-11T19:31:37.421954Z",
     "shell.execute_reply.started": "2022-02-11T19:31:37.411130Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from paddle_models.BoW import BoW\n",
    "from paddle_models.CNN import CNN\n",
    "from paddle_models.LSTM import LSTM\n",
    "from paddle_models.GRU import GRU\n",
    "\n",
    "\n",
    "def do_train_and_evaluate(train_path, \n",
    "                          network, \n",
    "                          epochs=\"3\", \n",
    "                          dev_path='dev.tsv', \n",
    "                          test_path='test.tsv', \n",
    "                          batch_size=64,\n",
    "                          save=False, \n",
    "                          save_dir='ckpt',\n",
    "                          device=\"gpu\", \n",
    "                          log_freq=500):\n",
    "    \n",
    "    paddle.set_device(device)\n",
    "    \n",
    "    if network.lower() == \"bow\":\n",
    "        model = BoW(len(V.vocab_to_idx), 2)\n",
    "        include_seq_len = False\n",
    "    elif network.lower() == 'cnn':\n",
    "        model = CNN(len(V.vocab_to_idx), 2)\n",
    "        include_seq_len = False\n",
    "    elif network.lower() == 'lstm':\n",
    "        model = LSTM(len(V.vocab_to_idx), 2)\n",
    "        include_seq_len = True\n",
    "    elif network.lower() == 'gru':\n",
    "        model = GRU(len(V.vocab_to_idx), 2)\n",
    "        include_seq_len = True\n",
    "    else:\n",
    "        raise ValueError(f\"Only supports: bow, cnn, lstm, gru, not {network}\")\n",
    "\n",
    "    train_set, dev_set, test_set = load_dataset([train_path, dev_path, test_path])\n",
    "    trans_fn = get_trans_fn(V, include_seq_len)\n",
    "    batchify_fn = get_batchify_fn(include_seq_len)\n",
    "    train_loader = create_dataloader(train_set, trans_fn, batchify_fn)\n",
    "    dev_loader = create_dataloader(dev_set, trans_fn, batchify_fn)\n",
    "    test_loader = create_dataloader(test_set, trans_fn, batchify_fn, shuffle=False)\n",
    "    \n",
    "    \n",
    "    model = get_model(model)\n",
    "    if save:\n",
    "        model.fit(train_loader, dev_loader, epochs=epochs, batch_size=batch_size, \n",
    "                  verbose=2, log_freq=log_freq, save_dir=save_dir)\n",
    "    else:\n",
    "        model.fit(train_loader, dev_loader, epochs=epochs, batch_size=batch_size,\n",
    "                  verbose=2, log_freq=log_freq)\n",
    "        \n",
    "    preds, labels = predict(model, test_loader)\n",
    "    accu, prec, recall, f1 = get_accu_pre_recall_f1(preds, labels)\n",
    "    \n",
    "    return [accu, prec, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-02-11T19:31:37.423451Z",
     "iopub.status.busy": "2022-02-11T19:31:37.423222Z",
     "iopub.status.idle": "2022-02-11T19:33:18.401279Z",
     "shell.execute_reply": "2022-02-11T19:33:18.400612Z",
     "shell.execute_reply.started": "2022-02-11T19:31:37.423430Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: full; Model: gru\n",
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/3\n",
      "step 109/109 - loss: 0.6052 - acc: 0.5447 - 22ms/step\n",
      "Eval begin...\n",
      "step 14/14 - loss: 0.5093 - acc: 0.7225 - 20ms/step\n",
      "Eval samples: 872\n",
      "Epoch 2/3\n",
      "step 109/109 - loss: 0.2066 - acc: 0.8249 - 22ms/step\n",
      "Eval begin...\n",
      "step 14/14 - loss: 0.4217 - acc: 0.7844 - 19ms/step\n",
      "Eval samples: 872\n",
      "Epoch 3/3\n",
      "step 109/109 - loss: 0.3137 - acc: 0.9389 - 22ms/step\n",
      "Eval begin...\n",
      "step 14/14 - loss: 0.4751 - acc: 0.7844 - 19ms/step\n",
      "Eval samples: 872\n",
      "Predict begin...\n",
      "step 29/29 [==============================] - ETA: 1s - 50ms/ste - ETA: 0s - 34ms/ste - ETA: 0s - 29ms/ste - ETA: 0s - 27ms/ste - ETA: 0s - 25ms/ste - ETA: 0s - 24ms/ste - ETA: 0s - 23ms/ste - ETA: 0s - 23ms/ste - ETA: 0s - 23ms/ste - ETA: 0s - 22ms/ste - ETA: 0s - 22ms/ste - ETA: 0s - 21ms/ste - ETA: 0s - 20ms/ste - ETA: 0s - 19ms/ste - 19ms/step          \n",
      "Predict samples: 1821\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "out = []\n",
    "\n",
    "for size in ['0.5k', '1k', '2k', '4k', 'full']:\n",
    "    for net in ['bow', 'cnn', 'lstm', 'gru']:\n",
    "        print(f\"Size: {size}; Model: {net}\")\n",
    "        res = do_train_and_evaluate(f'./all_data/train_{size}.txt', net, 3, device='gpu')\n",
    "        out.append(['base', 'None', net, size] + res)\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        columns = ['TrainType', 'EditType', 'ClfModel', 'TrainSize', 'Accuracy', 'Precision', 'Recall', 'F1']\n",
    "        df = pd.DataFrame(out, columns=columns)\n",
    "        df.to_excel('base_model_stats.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-11T19:33:18.456000Z",
     "iopub.status.busy": "2022-02-11T19:33:18.455550Z",
     "iopub.status.idle": "2022-02-11T19:48:41.830070Z",
     "shell.execute_reply": "2022-02-11T19:48:41.829418Z",
     "shell.execute_reply.started": "2022-02-11T19:33:18.455974Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aug_type:reda_ngram. Size: full; Model: gru\n",
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/3\n",
      "step 500/637 - loss: 0.2716 - acc: 0.8289 - 23ms/step\n",
      "step 637/637 - loss: 0.0980 - acc: 0.8564 - 23ms/step\n",
      "Eval begin...\n",
      "step 14/14 - loss: 0.5354 - acc: 0.7695 - 19ms/step\n",
      "Eval samples: 872\n",
      "Epoch 2/3\n",
      "step 500/637 - loss: 0.0759 - acc: 0.9702 - 23ms/step\n",
      "step 637/637 - loss: 0.0020 - acc: 0.9699 - 23ms/step\n",
      "Eval begin...\n",
      "step 14/14 - loss: 0.6863 - acc: 0.7626 - 19ms/step\n",
      "Eval samples: 872\n",
      "Epoch 3/3\n",
      "step 500/637 - loss: 0.0887 - acc: 0.9813 - 23ms/step\n",
      "step 637/637 - loss: 0.0925 - acc: 0.9816 - 23ms/step\n",
      "Eval begin...\n",
      "step 14/14 - loss: 1.5016 - acc: 0.7443 - 20ms/step\n",
      "Eval samples: 872\n",
      "Predict begin...\n",
      "step 29/29 [==============================] - ETA: 1s - 51ms/ste - ETA: 0s - 35ms/ste - ETA: 0s - 30ms/ste - ETA: 0s - 27ms/ste - ETA: 0s - 25ms/ste - ETA: 0s - 24ms/ste - ETA: 0s - 24ms/ste - ETA: 0s - 23ms/ste - ETA: 0s - 23ms/ste - ETA: 0s - 22ms/ste - ETA: 0s - 22ms/ste - ETA: 0s - 22ms/ste - ETA: 0s - 21ms/ste - ETA: 0s - 19ms/ste - 19ms/step          \n",
      "Predict samples: 1821\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "out = []\n",
    "\n",
    "for aug_type in ['reda', 'reda_ngram']:\n",
    "    for size in ['0.5k', '1k', '2k', '4k', 'full']:\n",
    "        for net in ['bow', 'cnn', 'lstm', 'gru']:\n",
    "            print(f\"aug_type:{aug_type}. Size: {size}; Model: {net}\")\n",
    "            res = do_train_and_evaluate(f'./all_data/train_{size}_aug_{aug_type}.txt', net, 3, device=\"gpu\")\n",
    "            out.append([aug_type, 'All', net, size] + res)\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            columns = ['TrainType', 'EditType', 'ClfModel', 'TrainSize', 'Accuracy', 'Precision', 'Recall', 'F1']\n",
    "            df = pd.DataFrame(out, columns=columns)\n",
    "            df.to_excel('aug_model_stats.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
