{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b2de580",
   "metadata": {},
   "source": [
    "## Text sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93136c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample, seed\n",
    "from utils import load_dataset\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6716c882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6920"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = load_dataset('../data/train.tsv')\n",
    "seed(175)\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8cc6174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_sampling(out_num):\n",
    "    return [t for t in sample(train, out_num)]\n",
    "\n",
    "\n",
    "def saveTextFile(data, filepath):\n",
    "    f = open(filepath, 'w')\n",
    "    tmp = \"\\n{}\\t{}\"\n",
    "    f.write(str(data[0][1]) + '\\t' + data[0][0])\n",
    "    for example in data[1:]:\n",
    "        f.write(tmp.format(str(example[1]), example[0]))\n",
    "    f.close()\n",
    "    print(filepath + \" has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf33c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "five_h = text_sampling(500)\n",
    "one_k = text_sampling(1000)\n",
    "two_k = text_sampling(2000)\n",
    "four_k = text_sampling(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7f3cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/aug_texts/train_0.5k.txt has been saved!\n",
      "../data/aug_texts/train_1k.txt has been saved!\n",
      "../data/aug_texts/train_2k.txt has been saved!\n",
      "../data/aug_texts/train_4k.txt has been saved!\n",
      "../data/aug_texts/train_full.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('../data/aug_texts/'):\n",
    "    os.mkdir('../data/aug_texts/')\n",
    "\n",
    "saveTextFile(five_h, '../data/aug_texts/train_0.5k.txt')\n",
    "saveTextFile(one_k, '../data/aug_texts/train_1k.txt')\n",
    "saveTextFile(two_k, '../data/aug_texts/train_2k.txt')\n",
    "saveTextFile(four_k, '../data/aug_texts/train_4k.txt')\n",
    "saveTextFile(train, '../data/aug_texts/train_full.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f462e",
   "metadata": {},
   "source": [
    "## Text Augmentation\n",
    "\n",
    "For every text pair, we will augment both texts and do cross pairing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7937d055",
   "metadata": {},
   "source": [
    "### DA models combined\n",
    "\n",
    "This is for two reasons: (1) efficiency; (2) more controlled, making sure that the augmented texts are sampled from the same pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "439301db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngramLM_en import NgramLM\n",
    "from reda_en import REDA\n",
    "from itertools import groupby\n",
    "from random import sample\n",
    "\n",
    "\n",
    "lm = NgramLM()\n",
    "\n",
    "\n",
    "class AugTextsWithTwoModels(REDA):\n",
    "    \n",
    "    def __int__(self, syn_path=None):\n",
    "        super.__init__(syn_path)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _out_num(edit_num, choice_num=None):\n",
    "        if choice_num:\n",
    "            return choice_num\n",
    "        if edit_num == 1:\n",
    "            return 20\n",
    "        if edit_num == 2:\n",
    "            return 50\n",
    "        if edit_num == 3:\n",
    "            return 100\n",
    "        return edit_num * 50\n",
    "    \n",
    "    @staticmethod\n",
    "    def deduplicate(ori, lst):\n",
    "        lst.append(ori)\n",
    "        lst.sort()\n",
    "        lst = [l for l,_ in groupby(lst)]\n",
    "        lst.remove(ori)\n",
    "        return lst\n",
    "    \n",
    "    def augment(self, text, replace_rate=0.2, swap_rate=0.2, \n",
    "                insert_rate=0.1, delete_rate=0.1, max_mix=None, \n",
    "                out_num_each=2, out_str=True):\n",
    "        \n",
    "        def _filter(item):\n",
    "            '''A func to make sure that the data structure is all right as some operation might fail to augment \n",
    "            the text (e.g., too short, no synonyms etc.)'''\n",
    "            if isinstance(item, str):\n",
    "                return []\n",
    "            if not out_str and isinstance(item[0], str):\n",
    "                if ''.join(item) == ''.join(words):\n",
    "                    return []\n",
    "                return [item]\n",
    "            return item\n",
    "        \n",
    "        if isinstance(text, str):\n",
    "            words = self.tokenize(text)\n",
    "        elif isinstance(text, list):\n",
    "            words = text\n",
    "        else:\n",
    "            raise TypeError(\"The input text must be either a str or a list\")\n",
    "            \n",
    "        words_num = len(words)\n",
    "        replace_num = round(replace_rate * words_num) \n",
    "        swap_num = round(swap_rate * words_num) \n",
    "        insert_num = round(insert_rate * words_num) \n",
    "        delete_num = round(delete_rate * words_num) \n",
    "        \n",
    "        reda_out = []\n",
    "        ngram_out = []\n",
    "        _sample = lambda lst, num: sample(lst, num) if len(lst) >= num else lst\n",
    "        out_num_each_special = out_num_each - 1 if out_num_each > 1 else out_num_each\n",
    "        \n",
    "        if replace_num:\n",
    "            out = _filter(self.replace_syn(words, replace_num, self._out_num(replace_num)))\n",
    "            reda_out.extend(_sample(out, out_num_each))\n",
    "            ngram_out.extend(lm.pickBestSent(out, out_num=out_num_each, out_str=out_str))\n",
    "        if swap_num:\n",
    "            out = _filter(self.swap_words(words, swap_num, self._out_num(swap_num)))\n",
    "            reda_out.extend(_sample(out, out_num_each))\n",
    "            ngram_out.extend(lm.pickBestSent(out, out_num=out_num_each, out_str=out_str))\n",
    "        if insert_num:\n",
    "            out = _filter(self.insert_words(words, insert_num, self._out_num(insert_num)))\n",
    "            reda_out.extend(_sample(out, out_num_each_special))\n",
    "            ngram_out.extend(lm.pickBestSent(out, out_num=out_num_each_special, out_str=out_str))\n",
    "        if delete_num:\n",
    "            out = _filter(self.delete_words(words, delete_num, self._out_num(delete_num)))\n",
    "            reda_out.extend(_sample(out, out_num_each_special))\n",
    "            ngram_out.extend(lm.pickBestSent(out, out_num=out_num_each_special, out_str=out_str))\n",
    "            \n",
    "        out = _filter(self.mixed_edits(words, 2, 50))\n",
    "        reda_out.extend(_sample(out, out_num_each_special))\n",
    "        ngram_out.extend(lm.pickBestSent(out, out_num=out_num_each_special, out_str=out_str))\n",
    "        \n",
    "        if out_str:\n",
    "            reda_out = [' '.join(sent) for sent in reda_out]\n",
    "        # to deduplicate the outputs and ensure that the original text is no returned.\n",
    "        words = self._out_str(words, out_str)\n",
    "        \n",
    "        reda_out = self.deduplicate(words, reda_out)\n",
    "        ngram_out = self.deduplicate(words, ngram_out)\n",
    "        return reda_out, ngram_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ecda904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textAugmentation(data, augModel, aug_num_each=2):\n",
    "    def augment(text, label):\n",
    "        out_reda = [(text, label)]\n",
    "        out_ngram = [(text, label)]\n",
    "        \n",
    "        aug_reda, aug_ngram = augModel.augment(text, out_num_each=aug_num_each)\n",
    "        out_reda.extend([(t, label) for t in aug_reda])\n",
    "        out_ngram.extend([(t, label) for t in aug_ngram])\n",
    "        \n",
    "        return out_reda, out_ngram\n",
    "    \n",
    "    outputs_reda, outputs_gram = [], []\n",
    "    for example in tqdm(data):\n",
    "        out_reda, out_ngram = augment(example[0], example[1])\n",
    "        outputs_reda.extend(out_reda)\n",
    "        outputs_gram.extend(out_ngram)\n",
    "    print('Texts augmented.')\n",
    "    print(f'Before (reda): {len(data)}. Now: {len(outputs_reda)}')\n",
    "    print(f'Before (ngram): {len(data)}. Now: {len(outputs_gram)}')\n",
    "    return outputs_reda, outputs_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "197b5ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = AugTextsWithTwoModels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb0054c",
   "metadata": {},
   "source": [
    "### 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9d0afb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [01:11<00:00,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 500. Now: 3953\n",
      "Before (ngram): 500. Now: 3936\n",
      "../data/aug_texts/train_0.5k_aug_reda.txt has been saved!\n",
      "../data/aug_texts/train_0.5_k_aug_reda_ngram.txt has been saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "five_h_aug_reda, five_h_aug_reda_ngram = textAugmentation(five_h, aug)\n",
    "saveTextFile(five_h_aug_reda, '../data/aug_texts/train_0.5k_aug_reda.txt')\n",
    "saveTextFile(five_h_aug_reda_ngram, '../data/aug_texts/train_0.5k_aug_reda_ngram.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9905bc23",
   "metadata": {},
   "source": [
    "### 1,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3b79957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [02:40<00:00,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 1000. Now: 7899\n",
      "Before (ngram): 1000. Now: 7859\n",
      "../data/aug_texts/train_1k_aug_reda.txt has been saved!\n",
      "../data/aug_texts/train_1k_aug_reda_ngram.txt has been saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "one_k_aug_reda, one_k_aug_reda_ngram = textAugmentation(one_k, aug)\n",
    "saveTextFile(one_k_aug_reda, '../data/aug_texts/train_1k_aug_reda.txt')\n",
    "saveTextFile(one_k_aug_reda_ngram, '../data/aug_texts/train_1k_aug_reda_ngram.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f9cef",
   "metadata": {},
   "source": [
    "### 2,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e391d7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2000/2000 [05:24<00:00,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 2000. Now: 15780\n",
      "Before (ngram): 2000. Now: 15702\n",
      "../data/aug_texts/train_2k_aug_reda.txt has been saved!\n",
      "../data/aug_texts/train_2k_aug_reda_ngram.txt has been saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "two_k_aug_reda, two_k_aug_reda_ngram = textAugmentation(two_k, aug)\n",
    "saveTextFile(two_k_aug_reda, '../data/aug_texts/train_2k_aug_reda.txt')\n",
    "saveTextFile(two_k_aug_reda_ngram, '../data/aug_texts/train_2k_aug_reda_ngram.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6985e07e",
   "metadata": {},
   "source": [
    "### 4,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77e52fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4000/4000 [10:01<00:00,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 4000. Now: 31585\n",
      "Before (ngram): 4000. Now: 31436\n",
      "../data/aug_texts/train_4k_aug_reda.txt has been saved!\n",
      "../data/aug_texts/train_4k_aug_reda_ngram.txt has been saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "four_k_aug_reda, four_k_aug_reda_ngram = textAugmentation(four_k, aug)\n",
    "saveTextFile(four_k_aug_reda, '../data/aug_texts/train_4k_aug_reda.txt')\n",
    "saveTextFile(four_k_aug_reda_ngram, '../data/aug_texts/train_4k_aug_reda_ngram.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1cd812",
   "metadata": {},
   "source": [
    "### Full\n",
    "\n",
    "The two augmented train sets for the entire train set were gotten from another running window. The statistics for them are reported below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0f53218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 6920/6920 [18:26<00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 6920. Now: 40883\n",
      "Before (ngram): 6920. Now: 40713\n",
      "../data/aug_texts/train_full_aug_reda.txt has been saved!\n",
      "../data/aug_texts/train_full_aug_reda_ngram.txt has been saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "full_aug_reda, full_aug_reda_ngram = textAugmentation(train, aug, aug_num_each=1)\n",
    "saveTextFile(full_aug_reda, '../data/aug_texts/train_full_aug_reda.txt')\n",
    "saveTextFile(full_aug_reda_ngram, '../data/aug_texts/train_full_aug_reda_ngram.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
