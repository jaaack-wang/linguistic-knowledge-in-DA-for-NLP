{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c5ad75d",
   "metadata": {},
   "source": [
    "## Text sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d613c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample, seed\n",
    "from utils import lcqmcLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "375f08a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = lcqmcLoader('train')\n",
    "seed(175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "119867ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_sampling(out_num):\n",
    "    return [t for t in sample(train, out_num)]\n",
    "\n",
    "\n",
    "def saveTextFile(data, filepath):\n",
    "    f = open(filepath, 'w')\n",
    "    f.write(\"text_a\\ttext_b\\tlabel\")\n",
    "    tmp = \"\\n{}\\t{}\\t{}\"\n",
    "    for example in data:\n",
    "        f.write(tmp.format(example[0], example[1], example[-1]))\n",
    "    f.close()\n",
    "    print(filepath + \" has been saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37073667",
   "metadata": {},
   "source": [
    "#### Dataset size to sample: 5k, 10k, 50k, 100k, and full set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a74356",
   "metadata": {},
   "outputs": [],
   "source": [
    "five_k = text_sampling(5000)\n",
    "ten_k = text_sampling(10000)\n",
    "fifty_k = text_sampling(50000)\n",
    "hundred_k = text_sampling(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02e3a428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/aug_texts/train_5k.txt has been saved!\n",
      "../data/aug_texts/train_10k.txt has been saved!\n",
      "../data/aug_texts/train_50k.txt has been saved!\n",
      "../data/aug_texts/train_100k.txt has been saved!\n",
      "../data/aug_texts/train_full.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "saveTextFile(five_k, '../data/aug_texts/train_5k.txt')\n",
    "saveTextFile(ten_k, '../data/aug_texts/train_10k.txt')\n",
    "saveTextFile(fifty_k, '../data/aug_texts/train_50k.txt')\n",
    "saveTextFile(hundred_k, '../data/aug_texts/train_100k.txt')\n",
    "saveTextFile(train, '../data/aug_texts/train_full.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b76fb4",
   "metadata": {},
   "source": [
    "## Text Augmentation\n",
    "\n",
    "For every text pair, we will augment both texts and do cross pairing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f49d1d",
   "metadata": {},
   "source": [
    "## DA models combined\n",
    "\n",
    "This is for two reasons: (1) efficiency; (2) more controlled, making sure that the augmented texts are sampled from the same pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8eccdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngramLM import NgramLM\n",
    "from reda import REDA\n",
    "from itertools import groupby\n",
    "from random import sample\n",
    "\n",
    "\n",
    "lm = NgramLM()\n",
    "\n",
    "\n",
    "class AugTextsWithTwoModels(REDA):\n",
    "    \n",
    "    def __int__(self, syn_path=None):\n",
    "        super.__init__(syn_path)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _out_num(edit_num, choice_num=None):\n",
    "        if choice_num:\n",
    "            return choice_num\n",
    "        if edit_num == 1:\n",
    "            return 20\n",
    "        if edit_num == 2:\n",
    "            return 50\n",
    "        if edit_num == 3:\n",
    "            return 100\n",
    "        return edit_num * 50\n",
    "    \n",
    "    @staticmethod\n",
    "    def deduplicate(ori, lst):\n",
    "        lst.append(ori)\n",
    "        lst.sort()\n",
    "        lst = [l for l,_ in groupby(lst)]\n",
    "        lst.remove(ori)\n",
    "        return lst\n",
    "    \n",
    "    def augment(self, text, replace_rate=0.2, swap_rate=0.2, \n",
    "                insert_rate=0.1, delete_rate=0.1, max_mix=None, \n",
    "                out_num_each=2, out_str=True):\n",
    "        \n",
    "        def _filter(item):\n",
    "            '''A func to make sure that the data structure is all right as some operation might fail to augment \n",
    "            the text (e.g., too short, no synonyms etc.)'''\n",
    "            if isinstance(item, str):\n",
    "                return []\n",
    "            if not out_str and isinstance(item[0], str):\n",
    "                if len(item) == len(words):\n",
    "                    for i in range(words_num):\n",
    "                        if item[i] == words[i]:\n",
    "                            return []\n",
    "                return [item]\n",
    "            return item\n",
    "        \n",
    "        if isinstance(text, str):\n",
    "            words = self.tokenize(text)\n",
    "        elif isinstance(text, list):\n",
    "            words = text\n",
    "        else:\n",
    "            raise TypeError(\"The input text must be either a str or a list\")\n",
    "            \n",
    "        words_num = len(words)\n",
    "        replace_num = round(replace_rate * words_num) \n",
    "        swap_num = round(swap_rate * words_num) \n",
    "        insert_num = round(insert_rate * words_num) \n",
    "        delete_num = round(delete_rate * words_num) \n",
    "        \n",
    "        reda_out = []\n",
    "        ngram_out = []\n",
    "        _sample = lambda lst, num: sample(lst, num) if len(lst) >= num else sample(lst, len(lst))\n",
    "        out_num_each_special = out_num_each - 1 if out_num_each > 1 else out_num_each\n",
    "        \n",
    "        if replace_num:\n",
    "            out = _filter(self.replace_syn(words, replace_num, self._out_num(replace_num)))\n",
    "            reda_out.extend(_sample(out, out_num_each))\n",
    "            ngram_out.extend(lm.pickBestSent(out, out_num=out_num_each, out_str=out_str))\n",
    "        if swap_num:\n",
    "            out = _filter(self.swap_words(words, swap_num, self._out_num(swap_num)))\n",
    "            reda_out.extend(_sample(out, out_num_each))\n",
    "            ngram_out.extend(lm.pickBestSent(out, out_num=out_num_each, out_str=out_str))\n",
    "        if insert_num:\n",
    "            out = _filter(self.insert_words(words, insert_num, self._out_num(insert_num)))\n",
    "            reda_out.extend(_sample(out, out_num_each_special))\n",
    "            ngram_out.extend(lm.pickBestSent(out, out_num=out_num_each_special, out_str=out_str))\n",
    "        if delete_num:\n",
    "            out = _filter(self.delete_words(words, delete_num, self._out_num(delete_num)))\n",
    "            reda_out.extend(_sample(out, out_num_each_special))\n",
    "            ngram_out.extend(lm.pickBestSent(out, out_num=out_num_each_special, out_str=out_str))\n",
    "            \n",
    "        out = _filter(self.mixed_edits(words, 2, 50, out_str))\n",
    "        reda_out.extend(_sample(out, out_num_each_special))\n",
    "        ngram_out.extend(lm.pickBestSent(out, out_num=out_num_each_special, out_str=out_str))\n",
    "        \n",
    "        if out_str:\n",
    "            reda_out = [''.join(sent) for sent in reda_out]\n",
    "        # to deduplicate the outputs and ensure that the original text is no returned.\n",
    "        words = self._out_str(words, out_str)\n",
    "        \n",
    "        reda_out = self.deduplicate(words, reda_out)\n",
    "        ngram_out = self.deduplicate(words, ngram_out)\n",
    "        return reda_out, ngram_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9186a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textAugmentation(data, augModel, aug_num_each=2):\n",
    "    def augment(text_a, text_b, label):\n",
    "        out_reda = [(text_a, text_b, label)]\n",
    "        out_ngram = [(text_a, text_b, label)]\n",
    "        \n",
    "        aug_reda, aug_ngram = augModel.augment(text_a, out_num_each=aug_num_each)\n",
    "        out_reda.extend([(t, text_b, label) for t in aug_reda])\n",
    "        out_ngram.extend([(t, text_b, label) for t in aug_ngram])\n",
    "        \n",
    "        aug_reda, aug_ngram = augModel.augment(text_b)\n",
    "        out_reda.extend([(t, text_b, label) for t in aug_reda])\n",
    "        out_ngram.extend([(t, text_b, label) for t in aug_ngram])\n",
    "        return out_reda, out_ngram\n",
    "    \n",
    "    if not isinstance(data[0], (tuple, list,)):\n",
    "        out_reda, out_ngram = augment(data[0], data[1], data[-1])\n",
    "        print('Texts augmented.')\n",
    "        print(f' Before (reda): 1. Now: {len(out_reda)}')\n",
    "        print(f' Before (ngram): 1. Now: {len(out_ngram)}')\n",
    "        return out_reda, out_ngram\n",
    "    \n",
    "    outputs_reda, outputs_gram = [], []\n",
    "    for example in data:\n",
    "        out_reda, out_ngram = augment(example[0], example[1], example[-1])\n",
    "        outputs_reda.extend(out_reda)\n",
    "        outputs_gram.extend(out_ngram)\n",
    "    print('Texts augmented.')\n",
    "    print(f'Before (reda): {len(data)}. Now: {len(outputs_reda)}')\n",
    "    print(f'Before (ngram): {len(data)}. Now: {len(outputs_gram)}')\n",
    "    return outputs_reda, outputs_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80bc558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = AugTextsWithTwoModels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e03607",
   "metadata": {},
   "source": [
    "### 5,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ced53df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/w9/d_nplhzj4qx35xxlgljgdtjh0000gn/T/jieba.cache\n",
      "Loading model cost 0.784 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 5000. Now: 66267\n",
      "Before (ngram): 5000. Now: 64358\n",
      "../data/aug_texts/train_5k_aug_reda.txt has been saved!\n",
      "../data/aug_texts/train_5k_aug_reda_ngram.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "five_k_aug_reda, five_k_aug_reda_ngram = textAugmentation(five_k, aug)\n",
    "saveTextFile(five_k_aug_reda, '../data/aug_texts/train_5k_aug_reda.txt')\n",
    "saveTextFile(five_k_aug_reda_ngram, '../data/aug_texts/train_5k_aug_reda_ngram.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18a8021",
   "metadata": {},
   "source": [
    "### 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6e4845a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 10000. Now: 132513\n",
      "Before (ngram): 10000. Now: 128649\n",
      "../data/aug_texts/train_10k_aug_reda.txt has been saved!\n",
      "../data/aug_texts/train_10k_aug_reda_ngram.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "ten_k_aug_reda, ten_k_aug_reda_ngram = textAugmentation(ten_k, aug)\n",
    "saveTextFile(ten_k_aug_reda, '../data/aug_texts/train_10k_aug_reda.txt')\n",
    "saveTextFile(ten_k_aug_reda_ngram, '../data/aug_texts/train_10k_aug_reda_ngram.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c988f8",
   "metadata": {},
   "source": [
    "### 50,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eabd0758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 50000. Now: 563228\n",
      "Before (ngram): 50000. Now: 544583\n",
      "../data/aug_texts/train_50k_aug_reda.txt has been saved!\n",
      "../data/aug_texts/train_50k_aug_reda_ngram.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "fifty_k_aug_reda, fifty_k_aug_reda_ngram = textAugmentation(fifty_k, aug, aug_num_each=1)\n",
    "saveTextFile(fifty_k_aug_reda, '../data/aug_texts/train_50k_aug_reda.txt')\n",
    "saveTextFile(fifty_k_aug_reda_ngram, '../data/aug_texts/train_50k_aug_reda_ngram.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fbf3ea",
   "metadata": {},
   "source": [
    "### 100,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0708b90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 100000. Now: 1127535\n",
      "Before (ngram): 100000. Now: 1089847\n",
      "../data/aug_texts/train_100k_aug_reda.txt has been saved!\n",
      "../data/aug_texts/train_100k_aug_reda_ngram.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "hundred_k_aug_reda, hundred_k_aug_reda_ngram = textAugmentation(hundred_k, aug, aug_num_each=1)\n",
    "saveTextFile(hundred_k_aug_reda, '../data/aug_texts/train_100k_aug_reda.txt')\n",
    "saveTextFile(hundred_k_aug_reda_ngram, '../data/aug_texts/train_100k_aug_reda_ngram.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f409a93",
   "metadata": {},
   "source": [
    "### Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5a55dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 238766. Now: 2691917\n",
      "Before (ngram): 238766. Now: 2601696\n",
      "../data/aug_texts/train_full_aug_reda.txt has been saved!\n",
      "../data/aug_texts/train_full_aug_reda_ngram.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "full_aug_reda, full_aug_reda_ngram = textAugmentation(train, aug, aug_num_each=1)\n",
    "saveTextFile(full_aug_reda, '../data/aug_texts/train_full_aug_reda.txt')\n",
    "saveTextFile(full_aug_reda_ngram, '../data/aug_texts/train_full_aug_reda_ngram.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
