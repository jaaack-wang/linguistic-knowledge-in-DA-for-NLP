{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83ced0ef",
   "metadata": {},
   "source": [
    "## Text sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ba238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample, seed\n",
    "from utils import lcqmcLoader\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f35e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = lcqmcLoader('train')\n",
    "seed(3245)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a70bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_sampling(out_num):\n",
    "    return [t for t in sample(train, out_num)]\n",
    "\n",
    "\n",
    "def saveTextFile(data, filepath):\n",
    "    f = open(filepath, 'w')\n",
    "    f.write(\"text_a\\ttext_b\\tlabel\")\n",
    "    tmp = \"\\n{}\\t{}\\t{}\"\n",
    "    for example in data:\n",
    "        f.write(tmp.format(example[0], example[1], example[-1]))\n",
    "    f.close()\n",
    "    print(filepath + \" has been saved!\")\n",
    "    \n",
    "def saveSampledTexts(out_num, dire):\n",
    "    data = text_sampling(out_num)\n",
    "    path = join(dire, f\"train_{int(out_num/1000)}k.txt\")\n",
    "    saveTextFile(data, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e79d0b",
   "metadata": {},
   "source": [
    "#### Dataset size to sample: 5k, 10k, 25k, 50k, 75k, 100k, 125k, 150k, 175k, 200k, full set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ba99d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/ablation_data/train_5k.txt has been saved!\n",
      "../data/ablation_data/train_10k.txt has been saved!\n",
      "../data/ablation_data/train_25k.txt has been saved!\n",
      "../data/ablation_data/train_50k.txt has been saved!\n",
      "../data/ablation_data/train_75k.txt has been saved!\n",
      "../data/ablation_data/train_100k.txt has been saved!\n",
      "../data/ablation_data/train_125k.txt has been saved!\n",
      "../data/ablation_data/train_150k.txt has been saved!\n",
      "../data/ablation_data/train_175k.txt has been saved!\n",
      "../data/ablation_data/train_200k.txt has been saved!\n",
      "../data/ablation_data/train_full.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "dire = '../data/ablation_data/'\n",
    "saveSampledTexts(5000, dire)\n",
    "saveSampledTexts(10000, dire)\n",
    "\n",
    "for i in range(25000, 200001, 25000):\n",
    "    saveSampledTexts(i, dire)\n",
    "\n",
    "saveTextFile(train, '../data/ablation_data/train_full.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af6e5f2",
   "metadata": {},
   "source": [
    "## Text Augmentation\n",
    "\n",
    "For every text pair, we will augment both texts and do cross pairing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141663a2",
   "metadata": {},
   "source": [
    "## DA models combined\n",
    "\n",
    "This is for two reasons: (1) efficiency; (2) more controlled, making sure that the augmented texts are sampled from the same pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bbd640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngramLM import NgramLM\n",
    "from reda import REDA\n",
    "from itertools import groupby\n",
    "from random import sample, shuffle\n",
    "\n",
    "\n",
    "class AugTextsWithTwoModels:\n",
    "    \n",
    "    def __init__(self, syn_path=None):\n",
    "        self._reda = REDA(syn_path)\n",
    "        self._lm = NgramLM()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _set_choice_num(edit_num, choice_num):\n",
    "        if choice_num:\n",
    "            return choice_num\n",
    "        if edit_num == 1:\n",
    "            return 20\n",
    "        if edit_num == 2:\n",
    "            return 50\n",
    "        if edit_num == 3:\n",
    "            return 100\n",
    "        if edit_num is None:\n",
    "            return 150\n",
    "        return edit_num * 50\n",
    "    \n",
    "    @staticmethod\n",
    "    def _out_num(edit_num, choice_num=None):\n",
    "        if choice_num:\n",
    "            return choice_num\n",
    "        if edit_num == 1:\n",
    "            return 20\n",
    "        if edit_num == 2:\n",
    "            return 50\n",
    "        if edit_num == 3:\n",
    "            return 100\n",
    "        return edit_num * 50\n",
    "    \n",
    "    @staticmethod\n",
    "    def deduplicate(ori, lst):\n",
    "        lst.append(ori)\n",
    "        lst.sort()\n",
    "        lst = [l for l,_ in groupby(lst)]\n",
    "        lst.remove(ori)\n",
    "        return lst\n",
    "\n",
    "    \n",
    "    def _textEdit(self, editFunc, words, edit_rate, out_num, out_str, choice_num):\n",
    "        \n",
    "        def _filter(item):\n",
    "            '''A func to make sure that the data structure is all right as some operation might fail to augment \n",
    "            the text (e.g., too short, no synonyms etc.)'''\n",
    "            if isinstance(item, str):\n",
    "                return []\n",
    "            if not out_str and isinstance(item[0], str):\n",
    "                if len(item) == len(words):\n",
    "                    for i in range(words_num):\n",
    "                        if item[i] == words[i]:\n",
    "                            return []\n",
    "                return [item]\n",
    "            return item\n",
    "        \n",
    "        if isinstance(words, str):\n",
    "            words = self._reda.tokenize(words)\n",
    "        elif isinstance(words, list):\n",
    "            pass\n",
    "        else:\n",
    "            raise TypeError(\"The input text must be either a str or a list\")\n",
    "        \n",
    "        \n",
    "        words_num = len(words)\n",
    "        \n",
    "        if isinstance(edit_rate, int):\n",
    "            edit_num = edit_rate\n",
    "        else:\n",
    "            edit_num = round(words_num * edit_rate)\n",
    "        \n",
    "        _sample = lambda lst, num: sample(lst, num) if len(lst) >= num else lst\n",
    "                \n",
    "        if edit_num:\n",
    "            choice_num = self._set_choice_num(edit_num, choice_num)\n",
    "            out = _filter(editFunc(words, edit_num, choice_num, out_str))\n",
    "            if out:\n",
    "                reda_out = _sample(out, out_num)\n",
    "                ngram_out = self._lm.pickBestSent(out, out_num=out_num, out_str=out_str)\n",
    "            else:\n",
    "                return [], []\n",
    "        else:\n",
    "            return [], []\n",
    "        \n",
    "        if out_str:\n",
    "            reda_out = [''.join(sent) for sent in reda_out]\n",
    "        # to deduplicate the outputs and ensure that the original text is no returned.\n",
    "        words = self._reda._out_str(words, out_str)\n",
    "        \n",
    "        reda_out = self.deduplicate(words, reda_out)\n",
    "        ngram_out = self.deduplicate(words, ngram_out)\n",
    "        \n",
    "        return reda_out, ngram_out\n",
    "    \n",
    "    def replace_syn(self, words, rpl_rate=0.2, out_num=1, out_str=True, choice_num=None):\n",
    "        return self._textEdit(self._reda.replace_syn, words, rpl_rate, out_num, out_str, choice_num)\n",
    "    \n",
    "    def swap_words(self, words, swap_rate=0.2, out_num=1, out_str=True, choice_num=None):\n",
    "        return self._textEdit(self._reda.swap_words, words, swap_rate, out_num, out_str, choice_num)\n",
    "    \n",
    "    def insert_words(self, words, insert_rate=0.1, out_num=1, out_str=True, choice_num=None):\n",
    "        return self._textEdit(self._reda.insert_words, words, insert_rate, out_num, out_str, choice_num)\n",
    "    \n",
    "    def delete_words(self, words, delete_rate=0.1, out_num=1, out_str=True, choice_num=None):\n",
    "        return self._textEdit(self._reda.delete_words, words, delete_rate, out_num, out_str, choice_num)\n",
    "    \n",
    "    def mixed_edits(self, words, max_mix=2, out_num=1, out_str=True, choice_num=None):\n",
    "        return self._textEdit(self._reda.mixed_edits, words, max_mix, out_num, out_str, choice_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d05408ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textAugmentation(data_size, editFunc, editName, out_num=2):\n",
    "    def augment(text_a, text_b, label):\n",
    "        out_reda = [(text_a, text_b, label)]\n",
    "        out_ngram = [(text_a, text_b, label)]\n",
    "        \n",
    "        aug_reda, aug_ngram = editFunc(text_a, out_num=out_num)\n",
    "        out_reda.extend([(t, text_b, label) for t in aug_reda])\n",
    "        out_ngram.extend([(t, text_b, label) for t in aug_ngram])\n",
    "        \n",
    "        aug_reda, aug_ngram = editFunc(text_b, out_num=out_num)\n",
    "        out_reda.extend([(text_a, t, label) for t in aug_reda])\n",
    "        out_ngram.extend([(text_a, t, label) for t in aug_ngram])\n",
    "        return out_reda, out_ngram\n",
    "    \n",
    "    if data_size not in ['5k', '10k', '25k', '50k']:\n",
    "        out_num = 1\n",
    "    \n",
    "    tmp = '../data/ablation_data/train_{}.txt'\n",
    "    data = open(tmp.format(data_size)).readlines()[1:]\n",
    "    \n",
    "    outputs_reda, outputs_gram = [], []\n",
    "    for example in data:\n",
    "        example = example.strip().split()\n",
    "        out_reda, out_ngram = augment(example[0], example[1], int(example[-1]))\n",
    "        outputs_reda.extend(out_reda)\n",
    "        outputs_gram.extend(out_ngram)\n",
    "    print('Texts augmented.')\n",
    "    print(f'Before (reda): {len(data)}. Now: {len(outputs_reda)}')\n",
    "    print(f'Before (ngram): {len(data)}. Now: {len(outputs_gram)}')\n",
    "    \n",
    "    del data\n",
    "    \n",
    "    saveTextFile(outputs_reda, tmp.format(f\"{data_size}_{editName}_reda\"))\n",
    "    saveTextFile(outputs_gram, tmp.format(f\"{data_size}_{editName}_reda_ngram\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e75c2c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = AugTextsWithTwoModels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23309913",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = ['5k', '10k', '25k', '50k', '75k', '100k', '125k', '150k', '175k', '200k', 'full']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1490213",
   "metadata": {},
   "source": [
    "### Synonym Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "219f86fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/w9/d_nplhzj4qx35xxlgljgdtjh0000gn/T/jieba.cache\n",
      "Loading model cost 0.786 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 5000. Now: 24402\n",
      "Before (ngram): 5000. Now: 24402\n",
      "../data/ablation_data/train_5k_sr_reda.txt has been saved!\n",
      "../data/ablation_data/train_5k_sr_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 10000. Now: 48807\n",
      "Before (ngram): 10000. Now: 48807\n",
      "../data/ablation_data/train_10k_sr_reda.txt has been saved!\n",
      "../data/ablation_data/train_10k_sr_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 25000. Now: 122358\n",
      "Before (ngram): 25000. Now: 122358\n",
      "../data/ablation_data/train_25k_sr_reda.txt has been saved!\n",
      "../data/ablation_data/train_25k_sr_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 50000. Now: 244577\n",
      "Before (ngram): 50000. Now: 244576\n",
      "../data/ablation_data/train_50k_sr_reda.txt has been saved!\n",
      "../data/ablation_data/train_50k_sr_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 75000. Now: 220843\n",
      "Before (ngram): 75000. Now: 220842\n",
      "../data/ablation_data/train_75k_sr_reda.txt has been saved!\n",
      "../data/ablation_data/train_75k_sr_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 100000. Now: 294516\n",
      "Before (ngram): 100000. Now: 294513\n",
      "../data/ablation_data/train_100k_sr_reda.txt has been saved!\n",
      "../data/ablation_data/train_100k_sr_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 125000. Now: 368078\n",
      "Before (ngram): 125000. Now: 368076\n",
      "../data/ablation_data/train_125k_sr_reda.txt has been saved!\n",
      "../data/ablation_data/train_125k_sr_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 150000. Now: 441643\n",
      "Before (ngram): 150000. Now: 441642\n",
      "../data/ablation_data/train_150k_sr_reda.txt has been saved!\n",
      "../data/ablation_data/train_150k_sr_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 175000. Now: 515229\n",
      "Before (ngram): 175000. Now: 515226\n",
      "../data/ablation_data/train_175k_sr_reda.txt has been saved!\n",
      "../data/ablation_data/train_175k_sr_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 200000. Now: 588901\n",
      "Before (ngram): 200000. Now: 588898\n",
      "../data/ablation_data/train_200k_sr_reda.txt has been saved!\n",
      "../data/ablation_data/train_200k_sr_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 238766. Now: 703077\n",
      "Before (ngram): 238766. Now: 703072\n",
      "../data/ablation_data/train_full_sr_reda.txt has been saved!\n",
      "../data/ablation_data/train_full_sr_reda_ngram.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "for size in data_size:\n",
    "    textAugmentation(size, aug.replace_syn, 'sr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724321c6",
   "metadata": {},
   "source": [
    "### Random Swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e10eabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 5000. Now: 24758\n",
      "Before (ngram): 5000. Now: 23549\n",
      "../data/ablation_data/train_5k_rs_reda.txt has been saved!\n",
      "../data/ablation_data/train_5k_rs_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 10000. Now: 49575\n",
      "Before (ngram): 10000. Now: 47268\n",
      "../data/ablation_data/train_10k_rs_reda.txt has been saved!\n",
      "../data/ablation_data/train_10k_rs_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 25000. Now: 124040\n",
      "Before (ngram): 25000. Now: 118154\n",
      "../data/ablation_data/train_25k_rs_reda.txt has been saved!\n",
      "../data/ablation_data/train_25k_rs_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 50000. Now: 248074\n",
      "Before (ngram): 50000. Now: 235953\n",
      "../data/ablation_data/train_50k_rs_reda.txt has been saved!\n",
      "../data/ablation_data/train_50k_rs_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 75000. Now: 223497\n",
      "Before (ngram): 75000. Now: 208583\n",
      "../data/ablation_data/train_75k_rs_reda.txt has been saved!\n",
      "../data/ablation_data/train_75k_rs_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 100000. Now: 297987\n",
      "Before (ngram): 100000. Now: 278291\n",
      "../data/ablation_data/train_100k_rs_reda.txt has been saved!\n",
      "../data/ablation_data/train_100k_rs_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 125000. Now: 372536\n",
      "Before (ngram): 125000. Now: 348084\n",
      "../data/ablation_data/train_125k_rs_reda.txt has been saved!\n",
      "../data/ablation_data/train_125k_rs_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 150000. Now: 446941\n",
      "Before (ngram): 150000. Now: 417589\n",
      "../data/ablation_data/train_150k_rs_reda.txt has been saved!\n",
      "../data/ablation_data/train_150k_rs_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 175000. Now: 521484\n",
      "Before (ngram): 175000. Now: 487053\n",
      "../data/ablation_data/train_175k_rs_reda.txt has been saved!\n",
      "../data/ablation_data/train_175k_rs_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 200000. Now: 595977\n",
      "Before (ngram): 200000. Now: 556635\n",
      "../data/ablation_data/train_200k_rs_reda.txt has been saved!\n",
      "../data/ablation_data/train_200k_rs_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 238766. Now: 711631\n",
      "Before (ngram): 238766. Now: 664727\n",
      "../data/ablation_data/train_full_rs_reda.txt has been saved!\n",
      "../data/ablation_data/train_full_rs_reda_ngram.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "for size in data_size:\n",
    "    textAugmentation(size, aug.swap_words, 'rs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26aa2fa",
   "metadata": {},
   "source": [
    "### Random Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d3a1ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 5000. Now: 16733\n",
      "Before (ngram): 5000. Now: 16733\n",
      "../data/ablation_data/train_5k_ri_reda.txt has been saved!\n",
      "../data/ablation_data/train_5k_ri_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 10000. Now: 33090\n",
      "Before (ngram): 10000. Now: 33090\n",
      "../data/ablation_data/train_10k_ri_reda.txt has been saved!\n",
      "../data/ablation_data/train_10k_ri_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 25000. Now: 83329\n",
      "Before (ngram): 25000. Now: 83329\n",
      "../data/ablation_data/train_25k_ri_reda.txt has been saved!\n",
      "../data/ablation_data/train_25k_ri_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 50000. Now: 166839\n",
      "Before (ngram): 50000. Now: 166839\n",
      "../data/ablation_data/train_50k_ri_reda.txt has been saved!\n",
      "../data/ablation_data/train_50k_ri_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 75000. Now: 162563\n",
      "Before (ngram): 75000. Now: 162563\n",
      "../data/ablation_data/train_75k_ri_reda.txt has been saved!\n",
      "../data/ablation_data/train_75k_ri_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 100000. Now: 216540\n",
      "Before (ngram): 100000. Now: 216540\n",
      "../data/ablation_data/train_100k_ri_reda.txt has been saved!\n",
      "../data/ablation_data/train_100k_ri_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 125000. Now: 270957\n",
      "Before (ngram): 125000. Now: 270957\n",
      "../data/ablation_data/train_125k_ri_reda.txt has been saved!\n",
      "../data/ablation_data/train_125k_ri_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 150000. Now: 325027\n",
      "Before (ngram): 150000. Now: 325027\n",
      "../data/ablation_data/train_150k_ri_reda.txt has been saved!\n",
      "../data/ablation_data/train_150k_ri_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 175000. Now: 379352\n",
      "Before (ngram): 175000. Now: 379352\n",
      "../data/ablation_data/train_175k_ri_reda.txt has been saved!\n",
      "../data/ablation_data/train_175k_ri_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 200000. Now: 433521\n",
      "Before (ngram): 200000. Now: 433521\n",
      "../data/ablation_data/train_200k_ri_reda.txt has been saved!\n",
      "../data/ablation_data/train_200k_ri_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 238766. Now: 517492\n",
      "Before (ngram): 238766. Now: 517492\n",
      "../data/ablation_data/train_full_ri_reda.txt has been saved!\n",
      "../data/ablation_data/train_full_ri_reda_ngram.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "for size in data_size:\n",
    "    textAugmentation(size, aug.insert_words, 'ri')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a822257",
   "metadata": {},
   "source": [
    "### Random Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07068b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 5000. Now: 16780\n",
      "Before (ngram): 5000. Now: 16780\n",
      "../data/ablation_data/train_5k_rd_reda.txt has been saved!\n",
      "../data/ablation_data/train_5k_rd_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 10000. Now: 33208\n",
      "Before (ngram): 10000. Now: 33208\n",
      "../data/ablation_data/train_10k_rd_reda.txt has been saved!\n",
      "../data/ablation_data/train_10k_rd_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 25000. Now: 83592\n",
      "Before (ngram): 25000. Now: 83592\n",
      "../data/ablation_data/train_25k_rd_reda.txt has been saved!\n",
      "../data/ablation_data/train_25k_rd_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 50000. Now: 167296\n",
      "Before (ngram): 50000. Now: 167296\n",
      "../data/ablation_data/train_50k_rd_reda.txt has been saved!\n",
      "../data/ablation_data/train_50k_rd_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 75000. Now: 162972\n",
      "Before (ngram): 75000. Now: 162972\n",
      "../data/ablation_data/train_75k_rd_reda.txt has been saved!\n",
      "../data/ablation_data/train_75k_rd_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 100000. Now: 217012\n",
      "Before (ngram): 100000. Now: 217012\n",
      "../data/ablation_data/train_100k_rd_reda.txt has been saved!\n",
      "../data/ablation_data/train_100k_rd_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 125000. Now: 271552\n",
      "Before (ngram): 125000. Now: 271552\n",
      "../data/ablation_data/train_125k_rd_reda.txt has been saved!\n",
      "../data/ablation_data/train_125k_rd_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 150000. Now: 325738\n",
      "Before (ngram): 150000. Now: 325738\n",
      "../data/ablation_data/train_150k_rd_reda.txt has been saved!\n",
      "../data/ablation_data/train_150k_rd_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 175000. Now: 380214\n",
      "Before (ngram): 175000. Now: 380214\n",
      "../data/ablation_data/train_175k_rd_reda.txt has been saved!\n",
      "../data/ablation_data/train_175k_rd_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 200000. Now: 434469\n",
      "Before (ngram): 200000. Now: 434469\n",
      "../data/ablation_data/train_200k_rd_reda.txt has been saved!\n",
      "../data/ablation_data/train_200k_rd_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 238766. Now: 518664\n",
      "Before (ngram): 238766. Now: 518664\n",
      "../data/ablation_data/train_full_rd_reda.txt has been saved!\n",
      "../data/ablation_data/train_full_rd_reda_ngram.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "for size in data_size:\n",
    "    textAugmentation(size, aug.delete_words, 'rd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a8cf6c",
   "metadata": {},
   "source": [
    "### Random Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a60704dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts augmented.\n",
      "Before (reda): 5000. Now: 24859\n",
      "Before (ngram): 5000. Now: 24464\n",
      "../data/ablation_data/train_5k_rm_reda.txt has been saved!\n",
      "../data/ablation_data/train_5k_rm_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 10000. Now: 49652\n",
      "Before (ngram): 10000. Now: 48783\n",
      "../data/ablation_data/train_10k_rm_reda.txt has been saved!\n",
      "../data/ablation_data/train_10k_rm_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 25000. Now: 124237\n",
      "Before (ngram): 25000. Now: 122106\n",
      "../data/ablation_data/train_25k_rm_reda.txt has been saved!\n",
      "../data/ablation_data/train_25k_rm_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 50000. Now: 248539\n",
      "Before (ngram): 50000. Now: 244371\n",
      "../data/ablation_data/train_50k_rm_reda.txt has been saved!\n",
      "../data/ablation_data/train_50k_rm_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 75000. Now: 224026\n",
      "Before (ngram): 75000. Now: 219342\n",
      "../data/ablation_data/train_75k_rm_reda.txt has been saved!\n",
      "../data/ablation_data/train_75k_rm_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 100000. Now: 298620\n",
      "Before (ngram): 100000. Now: 292580\n",
      "../data/ablation_data/train_100k_rm_reda.txt has been saved!\n",
      "../data/ablation_data/train_100k_rm_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 125000. Now: 373266\n",
      "Before (ngram): 125000. Now: 365555\n",
      "../data/ablation_data/train_125k_rm_reda.txt has been saved!\n",
      "../data/ablation_data/train_125k_rm_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 150000. Now: 447838\n",
      "Before (ngram): 150000. Now: 438630\n",
      "../data/ablation_data/train_150k_rm_reda.txt has been saved!\n",
      "../data/ablation_data/train_150k_rm_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 175000. Now: 522535\n",
      "Before (ngram): 175000. Now: 511878\n",
      "../data/ablation_data/train_175k_rm_reda.txt has been saved!\n",
      "../data/ablation_data/train_175k_rm_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 200000. Now: 597084\n",
      "Before (ngram): 200000. Now: 584858\n",
      "../data/ablation_data/train_200k_rm_reda.txt has been saved!\n",
      "../data/ablation_data/train_200k_rm_reda_ngram.txt has been saved!\n",
      "Texts augmented.\n",
      "Before (reda): 238766. Now: 712852\n",
      "Before (ngram): 238766. Now: 698483\n",
      "../data/ablation_data/train_full_rm_reda.txt has been saved!\n",
      "../data/ablation_data/train_full_rm_reda_ngram.txt has been saved!\n"
     ]
    }
   ],
   "source": [
    "for size in data_size:\n",
    "    textAugmentation(size, aug.mixed_edits, 'rm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
