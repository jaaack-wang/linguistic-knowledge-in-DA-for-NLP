{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5656d2",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25fb4e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ngramGenerator, readJson, lcqmcLoader\n",
    "from reda import REDA\n",
    "from ngramLM import NgramLM\n",
    "from random import sample, shuffle\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3973e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = NgramLM()\n",
    "reda = REDA()\n",
    "syn_dic = reda._syn.copy()\n",
    "train = lcqmcLoader('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe6c538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful utils funcs\n",
    "\n",
    "def random_sample(out_num=10000):\n",
    "    return [t[0] for t in sample(train, out_num)]\n",
    "\n",
    "def evaluate(eval_func, num_edits, num_choices, \n",
    "             num_run=5, num_sample=10000):\n",
    "    base_score, ngram_score = [], []\n",
    "    for _ in range(num_run):\n",
    "        res = eval_func(random_sample(num_sample), num_edits, num_choices)\n",
    "        print(res)\n",
    "        base_score.append(res['base_accu'])\n",
    "        ngram_score.append(res['ngram_accu'])\n",
    "        \n",
    "    base_avg = round(sum(base_score)/num_run, 2)\n",
    "    ngram_avg = round(sum(ngram_score)/num_run, 2)\n",
    "    return {'base_avg': base_avg, 'ngram_avg': ngram_avg}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22091c6d",
   "metadata": {},
   "source": [
    "### More about num_choices\n",
    "\n",
    "As the reda model generates novel text at random, so to make it possible that both models see the original texts after these text editing operations, we need to have enough number of output sentences. The average sentence length of LCQMC is about 6~7 words per question. Suppose there are on average 3 words that have synonyms in this experiment, then there are (4 + 4 + 4 = 12) possible replacements when `num_edits=1`, (4 * 8 + 4 * 4 = 48) possible replacements when `num_edits=2`, and (4 * 4 * 4 = 64) possible replacements when `num_edits=3`. \n",
    "\n",
    "For random swap, this is: 15 possible swaps when `num_edits=1`, 15 * 15 = 225 possible swaps when `num_edits=2`, and (6! = 720) possible swaps when `num_edits=3`.\n",
    "\n",
    "For random deletion (the sentence will first be added by the same number of tokens to delete), this is: 7 possible scenarios when when `num_edits=1`, 20 possible scenarios when when `num_edits=2`, 84 possible scenarios when when `num_edits=1`. This is a simple combination problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa53c3b",
   "metadata": {},
   "source": [
    "## Synonym Replacement Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76c08cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_syn_dic(syn_dic, unigram_dic, \n",
    "                   min_freq=1000, max_freq=2000, distractor_num=3):\n",
    "    freq_words = list(unigram_dic.keys())[min_freq: max_freq]\n",
    "    qseudo_dic = {}\n",
    "    for k in syn_dic.keys():\n",
    "        if k in freq_words:\n",
    "            fake_syn = [w for w in sample(freq_words, 20) if w not in syn_dic[k] + [k]]\n",
    "            fake_syn = sample(fake_syn, distractor_num)\n",
    "            qseudo_dic[k] = [k] + fake_syn\n",
    "            shuffle(qseudo_dic[k])\n",
    "    return qseudo_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3ff7aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qseudo_dic = pseudo_syn_dic(syn_dic, lm._unigram, 1000, 10001, distractor_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c5ad88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reda._syn = qseudo_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d92bb12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syn_rpl_test(samples, num_changes, num_choices):\n",
    "    base_right, ngram_right, total= 0, 0, 0\n",
    "    for text in samples:\n",
    "        tokens = reda.tokenize(text)\n",
    "        replaceable = reda._replaceable_idx(tokens)\n",
    "        if len(replaceable) >= num_changes:\n",
    "            total += 1\n",
    "            \n",
    "            choices = reda.replace_syn(tokens, num_changes, num_choices)\n",
    "            reda_text = sample(choices, 1)[0]\n",
    "            ngram_text = lm.pickBestSent(choices)\n",
    "            if ''.join(reda_text) == text:\n",
    "                base_right += 1\n",
    "            if ''.join(ngram_text) == text:\n",
    "                ngram_right += 1\n",
    "        \n",
    "    base_accu = round(base_right / total, 2)\n",
    "    ngram_accu = round(ngram_right / total, 2)\n",
    "    return {'base_accu': base_accu, 'ngram_accu': ngram_accu}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee62cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/w9/d_nplhzj4qx35xxlgljgdtjh0000gn/T/jieba.cache\n",
      "Loading model cost 0.679 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_accu': 0.22, 'ngram_accu': 0.88}\n",
      "{'base_accu': 0.22, 'ngram_accu': 0.88}\n",
      "{'base_accu': 0.22, 'ngram_accu': 0.88}\n",
      "{'base_accu': 0.21, 'ngram_accu': 0.89}\n",
      "{'base_accu': 0.22, 'ngram_accu': 0.88}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_avg': 0.22, 'ngram_avg': 0.88}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(syn_rpl_test, 1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed549bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_accu': 0.06, 'ngram_accu': 0.8}\n",
      "{'base_accu': 0.06, 'ngram_accu': 0.79}\n",
      "{'base_accu': 0.07, 'ngram_accu': 0.78}\n",
      "{'base_accu': 0.05, 'ngram_accu': 0.79}\n",
      "{'base_accu': 0.06, 'ngram_accu': 0.8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_avg': 0.06, 'ngram_avg': 0.79}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(syn_rpl_test, 2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffc9ee3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_accu': 0.01, 'ngram_accu': 0.64}\n",
      "{'base_accu': 0.01, 'ngram_accu': 0.62}\n",
      "{'base_accu': 0.02, 'ngram_accu': 0.64}\n",
      "{'base_accu': 0.02, 'ngram_accu': 0.64}\n",
      "{'base_accu': 0.02, 'ngram_accu': 0.64}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_avg': 0.02, 'ngram_avg': 0.64}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(syn_rpl_test, 3, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13034fe8",
   "metadata": {},
   "source": [
    "## Random swap Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b244072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ran_swap_test(samples, num_changes, num_choices):\n",
    "    base_right, ngram_right, total= 0, 0, 0\n",
    "    for text in samples:\n",
    "        tokens = jieba.lcut(text)\n",
    "    # it is less informative if there are less than 3 words \n",
    "        if len(tokens) > 2:\n",
    "            total += 1\n",
    "            \n",
    "            tokens = reda.swap_words(tokens, num_changes)\n",
    "            choices = reda.swap_words(tokens, num_changes, num_choices)\n",
    "            reda_text = sample(choices, 1)[0]\n",
    "            ngram_text = lm.pickBestSent(choices)\n",
    "            if ''.join(reda_text) == text:\n",
    "                base_right += 1\n",
    "            if ''.join(ngram_text) == text:\n",
    "                ngram_right += 1\n",
    "                \n",
    "    base_accu = round(base_right / total, 2)\n",
    "    ngram_accu = round(ngram_right / total, 2)\n",
    "    return {'base_accu': base_accu, 'ngram_accu': ngram_accu}           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b6c50c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_accu': 0.09, 'ngram_accu': 0.7}\n",
      "{'base_accu': 0.09, 'ngram_accu': 0.69}\n",
      "{'base_accu': 0.1, 'ngram_accu': 0.69}\n",
      "{'base_accu': 0.09, 'ngram_accu': 0.7}\n",
      "{'base_accu': 0.09, 'ngram_accu': 0.69}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_avg': 0.09, 'ngram_avg': 0.69}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ran_swap_test, 1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e868cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_accu': 0.04, 'ngram_accu': 0.4}\n",
      "{'base_accu': 0.04, 'ngram_accu': 0.41}\n",
      "{'base_accu': 0.04, 'ngram_accu': 0.41}\n",
      "{'base_accu': 0.04, 'ngram_accu': 0.41}\n",
      "{'base_accu': 0.04, 'ngram_accu': 0.41}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_avg': 0.04, 'ngram_avg': 0.41}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ran_swap_test, 2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7375c65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_accu': 0.04, 'ngram_accu': 0.34}\n",
      "{'base_accu': 0.04, 'ngram_accu': 0.34}\n",
      "{'base_accu': 0.04, 'ngram_accu': 0.33}\n",
      "{'base_accu': 0.04, 'ngram_accu': 0.34}\n",
      "{'base_accu': 0.04, 'ngram_accu': 0.34}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_avg': 0.04, 'ngram_avg': 0.34}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ran_swap_test, 3, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42af6354",
   "metadata": {},
   "source": [
    "## Random delete Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e574bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ran_delete_test(samples, num_changes, num_choices):\n",
    "    base_right, ngram_right, total= 0, 0, 0\n",
    "    for text in samples:\n",
    "        tokens = jieba.lcut(text)\n",
    "    # it is less informative if there are less than 6 words \n",
    "        if len(tokens) > num_changes:\n",
    "            total += 1\n",
    "            \n",
    "            tokens += sample(tokens, num_changes)\n",
    "            choices = reda.delete_words(tokens, num_changes, num_choices)\n",
    "            reda_text = sample(choices, 1)[0]\n",
    "            ngram_text = lm.pickBestSent(choices)\n",
    "            \n",
    "            if ''.join(reda_text) == text:\n",
    "                base_right += 1\n",
    "            if ''.join(ngram_text) == text:\n",
    "                ngram_right += 1\n",
    "\n",
    "    base_accu = round(base_right / total, 2)\n",
    "    ngram_accu = round(ngram_right / total, 2)\n",
    "    return {'base_accu': base_accu, 'ngram_accu': ngram_accu}           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f414b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_accu': 0.15, 'ngram_accu': 0.39}\n",
      "{'base_accu': 0.16, 'ngram_accu': 0.39}\n",
      "{'base_accu': 0.16, 'ngram_accu': 0.39}\n",
      "{'base_accu': 0.16, 'ngram_accu': 0.39}\n",
      "{'base_accu': 0.16, 'ngram_accu': 0.39}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_avg': 0.16, 'ngram_avg': 0.39}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ran_delete_test, 1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d979a56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_accu': 0.05, 'ngram_accu': 0.23}\n",
      "{'base_accu': 0.05, 'ngram_accu': 0.22}\n",
      "{'base_accu': 0.05, 'ngram_accu': 0.22}\n",
      "{'base_accu': 0.05, 'ngram_accu': 0.22}\n",
      "{'base_accu': 0.05, 'ngram_accu': 0.22}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_avg': 0.05, 'ngram_avg': 0.22}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ran_delete_test, 2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5be51d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_accu': 0.02, 'ngram_accu': 0.15}\n",
      "{'base_accu': 0.02, 'ngram_accu': 0.15}\n",
      "{'base_accu': 0.02, 'ngram_accu': 0.15}\n",
      "{'base_accu': 0.02, 'ngram_accu': 0.14}\n",
      "{'base_accu': 0.02, 'ngram_accu': 0.14}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_avg': 0.02, 'ngram_avg': 0.15}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ran_delete_test, 3, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7380c0",
   "metadata": {},
   "source": [
    "## Additional evaluation methods for random swap\n",
    "\n",
    "Do not change anything. Simply randomly swap the word order two times and check which output text is closer to the original one by ngramoverlap and edit distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2b930f",
   "metadata": {},
   "source": [
    "## Ngramoverlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54837889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngramOverlapCoef(tokens1, tokens2, ngram, digits=2):\n",
    "    tokens1 = ngramGenerator(tokens1, ngram)\n",
    "    tokens2 = ngramGenerator(tokens2, ngram)\n",
    "    avgLen = len(tokens1 + tokens2) / 2\n",
    "    sharedLen = 0\n",
    "    for i in tokens1:\n",
    "        if i in tokens2:\n",
    "            sharedLen += 1\n",
    "            tokens2.remove(i)\n",
    "    return round(sharedLen / avgLen, digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bc143d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ran_swap_test2(samples, num_changes, num_choices, ngram=2):\n",
    "    assert num_changes > 1, 'num_changes should be at least greater than 1'\n",
    "    res_base = []\n",
    "    res_ngram = []\n",
    "    for text in samples:\n",
    "        tokens = jieba.lcut(text)\n",
    "    # it is less informative if there are less than 3 words \n",
    "        if len(tokens) > 2:\n",
    "            choices = reda.swap_words(tokens, num_changes, num_choices)\n",
    "            reda_text = sample(choices, 1)[0]\n",
    "            ngram_text = lm.pickBestSent(choices, out_str=False)[0]\n",
    "            res_base.append(ngramOverlapCoef(tokens, reda_text, ngram))\n",
    "            res_ngram.append(ngramOverlapCoef(tokens, ngram_text, ngram))\n",
    "            \n",
    "    base_avg = sum(res_base) / len(res_base)\n",
    "    ngram_avg = sum(res_ngram) / len(res_ngram)\n",
    "    return {'base_avg': base_avg, 'ngram_avg': ngram_avg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5f91702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_avg': 0.2890173177607697, 'ngram_avg': 0.7676409585179205}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran_swap_test2(random_sample(), 2, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84810c5",
   "metadata": {},
   "source": [
    "## Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bfcdff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def editDistDP(str1, str2, digits=2):\n",
    "    m = len(str1)\n",
    "    n = len(str2)\n",
    "    dp = [[0 for x in range(n+1)] for x in range(m+1)]\n",
    "    \n",
    "    for i in range(m+1):\n",
    "        for j in range(n+1):\n",
    "            if i == 0:\n",
    "                dp[i][j] = j\n",
    "            elif j == 0:\n",
    "                dp[i][j] = i\n",
    "                \n",
    "            elif str1[i-1] == str2[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    "                \n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i][j-1], # insert\n",
    "                                   dp[i-1][j], # remove\n",
    "                                   dp[i-1][j-1]) # replace\n",
    "    # the min distance         \n",
    "    return dp[m][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65bcf1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ran_swap_test3(samples, num_changes, num_choices, ngram=2):\n",
    "    assert num_changes > 1, 'num_changes should be at least greater than 1'\n",
    "    res_base = []\n",
    "    res_ngram = []\n",
    "    for text in samples:\n",
    "        tokens = jieba.lcut(text)\n",
    "    # it is less informative if there are less than 3 words \n",
    "        if len(tokens) > 2:\n",
    "            choices = reda.swap_words(tokens, num_changes, num_choices)\n",
    "            reda_text = sample(choices, 1)[0]\n",
    "            ngram_text = lm.pickBestSent(choices, out_str=False)[0]\n",
    "            res_base.append(editDistDP(tokens, reda_text, ngram))\n",
    "            res_ngram.append(editDistDP(tokens, ngram_text, ngram))\n",
    "            \n",
    "    base_avg = sum(res_base) / len(res_base)\n",
    "    ngram_avg = sum(res_ngram) / len(res_ngram)\n",
    "    return {'base_avg': base_avg, 'ngram_avg': ngram_avg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12c3e585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_avg': 2.9825020112630733, 'ngram_avg': 1.3791230893000805}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran_swap_test3(random_sample(), 2, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
