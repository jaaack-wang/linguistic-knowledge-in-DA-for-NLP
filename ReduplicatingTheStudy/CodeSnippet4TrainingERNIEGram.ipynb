{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6066d18f-1055-400c-9e41-e81afd32d0fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T06:30:15.824471Z",
     "iopub.status.busy": "2021-12-05T06:30:15.823958Z",
     "iopub.status.idle": "2021-12-05T06:30:15.827359Z",
     "shell.execute_reply": "2021-12-05T06:30:15.826823Z",
     "shell.execute_reply.started": "2021-12-05T06:30:15.824441Z"
    }
   },
   "outputs": [],
   "source": [
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfe8e313-6f91-48ce-a6f2-1113a1a33565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T06:30:16.336594Z",
     "iopub.status.busy": "2021-12-05T06:30:16.335699Z",
     "iopub.status.idle": "2021-12-05T06:30:16.347997Z",
     "shell.execute_reply": "2021-12-05T06:30:16.347367Z",
     "shell.execute_reply.started": "2021-12-05T06:30:16.336556Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(data_size, aug_type, ep=3):\n",
    "    if exists('./checkpoints'):\n",
    "        !rm -r ./checkpoints\n",
    "    \n",
    "    if aug_type == 'reda':\n",
    "        train_set_suffix = f\"_{data_size}_aug_reda\"\n",
    "    else:\n",
    "        train_set_suffix = f\"_{data_size}_aug_reda_ngram\"\n",
    "\n",
    "    train_set_path = './train' + train_set_suffix + '.txt'\n",
    "\n",
    "    !python -u -m paddle.distributed.launch --gpus \"0\" train_pointwise.py \\\n",
    "            --train_set_path {train_set_path} \\\n",
    "            --dev_set_path './dev.txt' \\\n",
    "            --epochs {ep} \\\n",
    "            --save_dir ./checkpoints\\\n",
    "            --batch_size 64 \\\n",
    "            --learning_rate 2E-5 \\\n",
    "    \n",
    "    model = !ls ./checkpoints/\n",
    "    model.sort()\n",
    "    model_path = f\"./checkpoints/{model[-1]}/model_state.pdparams\"\n",
    "\n",
    "    !python -u -m paddle.distributed.launch --gpus \"0\" \\\n",
    "            predict_pointwise.py \\\n",
    "            --out_dir './test_preds/' \\\n",
    "            --train_set_suffix {train_set_suffix} \\\n",
    "            --device gpu \\\n",
    "            --params_path {model_path}\\\n",
    "            --batch_size 64 \\\n",
    "            --max_seq_length 128 \\\n",
    "            --input_file 'test.txt'\n",
    "    \n",
    "    !rm train_set_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad1df4a7-2b6e-44bc-9a0d-a2ffa5c27556",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T06:30:17.420597Z",
     "iopub.status.busy": "2021-12-05T06:30:17.419716Z",
     "iopub.status.idle": "2021-12-05T06:52:57.052826Z",
     "shell.execute_reply": "2021-12-05T06:52:57.052048Z",
     "shell.execute_reply.started": "2021-12-05T06:30:17.420558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------  Configuration Arguments -----------\n",
      "backend: auto\n",
      "elastic_server: None\n",
      "force: False\n",
      "gpus: 0\n",
      "heter_worker_num: None\n",
      "heter_workers: \n",
      "host: None\n",
      "http_port: None\n",
      "ips: 127.0.0.1\n",
      "job_id: None\n",
      "log_dir: log\n",
      "np: None\n",
      "nproc_per_node: None\n",
      "run_mode: None\n",
      "scale: 0\n",
      "server_num: None\n",
      "servers: \n",
      "training_script: train_pointwise.py\n",
      "training_script_args: ['--train_set_path', './train_5k_aug_reda.txt', '--dev_set_path', './dev.txt', '--epochs', '3', '--save_dir', './checkpoints', '--batch_size', '64', '--learning_rate', '2E-5']\n",
      "worker_num: None\n",
      "workers: \n",
      "------------------------------------------------\n",
      "WARNING 2021-12-05 14:30:19,426 launch.py:416] Not found distinct arguments and compiled with cuda or xpu. Default use collective mode\n",
      "launch train in GPU mode!\n",
      "INFO 2021-12-05 14:30:19,428 launch_utils.py:527] Local start 1 processes. First process distributed environment info (Only For Debug): \n",
      "    +=======================================================================================+\n",
      "    |                        Distributed Envs                      Value                    |\n",
      "    +---------------------------------------------------------------------------------------+\n",
      "    |                       PADDLE_TRAINER_ID                        0                      |\n",
      "    |                 PADDLE_CURRENT_ENDPOINT                 127.0.0.1:34088               |\n",
      "    |                     PADDLE_TRAINERS_NUM                        1                      |\n",
      "    |                PADDLE_TRAINER_ENDPOINTS                 127.0.0.1:34088               |\n",
      "    |                     PADDLE_RANK_IN_NODE                        0                      |\n",
      "    |                 PADDLE_LOCAL_DEVICE_IDS                        0                      |\n",
      "    |                 PADDLE_WORLD_DEVICE_IDS                        0                      |\n",
      "    |                     FLAGS_selected_gpus                        0                      |\n",
      "    |             FLAGS_selected_accelerators                        0                      |\n",
      "    +=======================================================================================+\n",
      "\n",
      "INFO 2021-12-05 14:30:19,428 launch_utils.py:531] details abouts PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0\n",
      "launch proc_id:278 idx:0\n",
      "[2021-12-05 14:30:21,254] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/ernie_gram_zh/ernie_gram_zh.pdparams and saved to /home/aistudio/.paddlenlp/models/ernie-gram-zh\n",
      "[2021-12-05 14:30:21,254] [    INFO] - Downloading ernie_gram_zh.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/ernie_gram_zh/ernie_gram_zh.pdparams\n",
      "\n",
      "  0%|          | 0/583566 [00:00<?, ?it/s]\n",
      "  0%|          | 1395/583566 [00:00<00:41, 13936.06it/s]\n",
      "  1%|          | 6544/583566 [00:00<00:32, 17839.29it/s]\n",
      "  2%|▏         | 12545/583566 [00:00<00:25, 22604.63it/s]\n",
      "  3%|▎         | 18484/583566 [00:00<00:20, 27763.50it/s]\n",
      "  4%|▍         | 25217/583566 [00:00<00:16, 33705.61it/s]\n",
      "  6%|▌         | 32123/583566 [00:00<00:13, 39821.15it/s]\n",
      "  7%|▋         | 39173/583566 [00:00<00:11, 45798.67it/s]\n",
      "  8%|▊         | 46029/583566 [00:00<00:10, 50864.26it/s]\n",
      "  9%|▉         | 52947/583566 [00:00<00:09, 55250.03it/s]\n",
      " 10%|█         | 59991/583566 [00:01<00:08, 59070.12it/s]\n",
      " 12%|█▏        | 67120/583566 [00:01<00:08, 62272.07it/s]\n",
      " 13%|█▎        | 74426/583566 [00:01<00:07, 65158.28it/s]\n",
      " 14%|█▍        | 81797/583566 [00:01<00:07, 67503.13it/s]\n",
      " 15%|█▌        | 89193/583566 [00:01<00:07, 69315.07it/s]\n",
      " 17%|█▋        | 96625/583566 [00:01<00:06, 70736.86it/s]\n",
      " 18%|█▊        | 103927/583566 [00:01<00:06, 71406.24it/s]\n",
      " 19%|█▉        | 111302/583566 [00:01<00:06, 72093.14it/s]\n",
      " 20%|██        | 118610/583566 [00:01<00:06, 72384.31it/s]\n",
      " 22%|██▏       | 126073/583566 [00:01<00:06, 73039.83it/s]\n",
      " 23%|██▎       | 133457/583566 [00:02<00:06, 73277.40it/s]\n",
      " 24%|██▍       | 140872/583566 [00:02<00:06, 73535.78it/s]\n",
      " 25%|██▌       | 148263/583566 [00:02<00:05, 73645.94it/s]\n",
      " 27%|██▋       | 155643/583566 [00:02<00:05, 73564.28it/s]\n",
      " 28%|██▊       | 163039/583566 [00:02<00:05, 73681.63it/s]\n",
      " 29%|██▉       | 170425/583566 [00:02<00:05, 73734.44it/s]\n",
      " 30%|███       | 177804/583566 [00:02<00:05, 73716.71it/s]\n",
      " 32%|███▏      | 185180/583566 [00:02<00:05, 73659.09it/s]\n",
      " 33%|███▎      | 192576/583566 [00:02<00:05, 73747.60it/s]\n",
      " 34%|███▍      | 199953/583566 [00:02<00:05, 73588.68it/s]\n",
      " 36%|███▌      | 207345/583566 [00:03<00:05, 73680.33it/s]\n",
      " 37%|███▋      | 214714/583566 [00:03<00:05, 73560.35it/s]\n",
      " 38%|███▊      | 222071/583566 [00:03<00:04, 72898.79it/s]\n",
      " 39%|███▉      | 229366/583566 [00:03<00:04, 72912.91it/s]\n",
      " 41%|████      | 236711/583566 [00:03<00:04, 73072.71it/s]\n",
      " 42%|████▏     | 244150/583566 [00:03<00:04, 73459.10it/s]\n",
      " 43%|████▎     | 251498/583566 [00:03<00:04, 73461.98it/s]\n",
      " 44%|████▍     | 258881/583566 [00:03<00:04, 73557.23it/s]\n",
      " 46%|████▌     | 266238/583566 [00:03<00:04, 73413.76it/s]\n",
      " 47%|████▋     | 273580/583566 [00:03<00:04, 73265.58it/s]\n",
      " 48%|████▊     | 280962/583566 [00:04<00:04, 73430.84it/s]\n",
      " 49%|████▉     | 288359/583566 [00:04<00:04, 73590.73it/s]\n",
      " 51%|█████     | 295719/583566 [00:04<00:03, 73463.29it/s]\n",
      " 52%|█████▏    | 303084/583566 [00:04<00:03, 73515.60it/s]\n",
      " 53%|█████▎    | 310436/583566 [00:04<00:03, 73475.37it/s]\n",
      " 54%|█████▍    | 317784/583566 [00:04<00:03, 73393.16it/s]\n",
      " 56%|█████▌    | 325146/583566 [00:04<00:03, 73459.62it/s]\n",
      " 57%|█████▋    | 332493/583566 [00:04<00:03, 73224.79it/s]\n",
      " 58%|█████▊    | 339816/583566 [00:04<00:03, 73051.29it/s]\n",
      " 59%|█████▉    | 347130/583566 [00:04<00:03, 73075.92it/s]\n",
      " 61%|██████    | 354481/583566 [00:05<00:03, 73192.28it/s]\n",
      " 62%|██████▏   | 361819/583566 [00:05<00:03, 73248.41it/s]\n",
      " 63%|██████▎   | 369203/583566 [00:05<00:02, 73423.50it/s]\n",
      " 65%|██████▍   | 376546/583566 [00:05<00:02, 73281.97it/s]\n",
      " 66%|██████▌   | 383875/583566 [00:05<00:02, 73256.73it/s]\n",
      " 67%|██████▋   | 391210/583566 [00:05<00:02, 73282.98it/s]\n",
      " 68%|██████▊   | 398539/583566 [00:05<00:02, 73269.60it/s]\n",
      " 70%|██████▉   | 405977/583566 [00:05<00:02, 73595.49it/s]\n",
      " 71%|███████   | 413337/583566 [00:05<00:02, 60265.29it/s]\n",
      " 72%|███████▏  | 420420/583566 [00:05<00:02, 63087.34it/s]\n",
      " 73%|███████▎  | 427333/583566 [00:06<00:02, 64783.99it/s]\n",
      " 74%|███████▍  | 434238/583566 [00:06<00:02, 66007.33it/s]\n",
      " 76%|███████▌  | 441413/583566 [00:06<00:02, 67628.97it/s]\n",
      " 77%|███████▋  | 448532/583566 [00:06<00:01, 68658.66it/s]\n",
      " 78%|███████▊  | 455826/583566 [00:06<00:01, 69888.35it/s]\n",
      " 79%|███████▉  | 463091/583566 [00:06<00:01, 70692.50it/s]\n",
      " 81%|████████  | 470465/583566 [00:06<00:01, 71572.24it/s]\n",
      " 82%|████████▏ | 477825/583566 [00:06<00:01, 72164.35it/s]\n",
      " 83%|████████▎ | 485144/583566 [00:06<00:01, 72466.98it/s]\n",
      " 84%|████████▍ | 492493/583566 [00:06<00:01, 72768.12it/s]\n",
      " 86%|████████▌ | 499793/583566 [00:07<00:01, 72833.13it/s]\n",
      " 87%|████████▋ | 507087/583566 [00:07<00:01, 72858.52it/s]\n",
      " 88%|████████▊ | 514463/583566 [00:07<00:00, 73124.90it/s]\n",
      " 89%|████████▉ | 521887/583566 [00:07<00:00, 73454.98it/s]\n",
      " 91%|█████████ | 529249/583566 [00:07<00:00, 73497.03it/s]\n",
      " 92%|█████████▏| 536641/583566 [00:07<00:00, 73618.50it/s]\n",
      " 93%|█████████▎| 544005/583566 [00:07<00:00, 73583.98it/s]\n",
      " 94%|█████████▍| 551365/583566 [00:07<00:00, 73238.15it/s]\n",
      " 96%|█████████▌| 558751/583566 [00:07<00:00, 73422.84it/s]\n",
      " 97%|█████████▋| 566157/583566 [00:07<00:00, 73610.55it/s]\n",
      " 98%|█████████▊| 573529/583566 [00:08<00:00, 73640.37it/s]\n",
      "100%|█████████▉| 580897/583566 [00:08<00:00, 73643.91it/s]\n",
      "100%|██████████| 583566/583566 [00:08<00:00, 70960.65it/s]\n",
      "W1205 14:30:29.612118   278 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1205 14:30:29.617413   278 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
      "[2021-12-05 14:30:39,044] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/ernie_gram_zh/vocab.txt and saved to /home/aistudio/.paddlenlp/models/ernie-gram-zh\n",
      "[2021-12-05 14:30:39,044] [    INFO] - Downloading vocab.txt from https://paddlenlp.bj.bcebos.com/models/transformers/ernie_gram_zh/vocab.txt\n",
      "\n",
      "  0%|          | 0/78 [00:00<?, ?it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 1920.13it/s]\n",
      "global step 500, epoch: 1, batch: 500, loss: 0.09337, accu: 0.86091, speed: 0.10 step/s\n",
      "global step 1000, epoch: 1, batch: 1000, loss: 0.05808, accu: 0.90552, speed: 0.10 step/s\n",
      "eval dev loss: 0.5921, accu: 0.83879\n",
      "global step 1500, epoch: 2, batch: 464, loss: 0.02901, accu: 0.97654, speed: 0.09 step/s\n",
      "global step 2000, epoch: 2, batch: 964, loss: 0.01206, accu: 0.98116, speed: 0.10 step/s\n",
      "eval dev loss: 1.0328, accu: 0.80016\n",
      "global step 2500, epoch: 3, batch: 428, loss: 0.00992, accu: 0.98974, speed: 0.09 step/s\n",
      "global step 3000, epoch: 3, batch: 928, loss: 0.00308, accu: 0.99071, speed: 0.10 step/s\n",
      "eval dev loss: 1.024, accu: 0.80925\n",
      "INFO 2021-12-05 14:41:23,068 launch.py:304] Local processes completed.\n",
      "-----------  Configuration Arguments -----------\n",
      "backend: auto\n",
      "elastic_server: None\n",
      "force: False\n",
      "gpus: 0\n",
      "heter_worker_num: None\n",
      "heter_workers: \n",
      "host: None\n",
      "http_port: None\n",
      "ips: 127.0.0.1\n",
      "job_id: None\n",
      "log_dir: log\n",
      "np: None\n",
      "nproc_per_node: None\n",
      "run_mode: None\n",
      "scale: 0\n",
      "server_num: None\n",
      "servers: \n",
      "training_script: predict_pointwise.py\n",
      "training_script_args: ['--out_dir', './test_preds/', '--train_set_suffix', '_5k_aug_reda', '--device', 'gpu', '--params_path', './checkpoints/model_3108/model_state.pdparams', '--batch_size', '64', '--max_seq_length', '128', '--input_file', 'test.txt']\n",
      "worker_num: None\n",
      "workers: \n",
      "------------------------------------------------\n",
      "WARNING 2021-12-05 14:41:24,934 launch.py:416] Not found distinct arguments and compiled with cuda or xpu. Default use collective mode\n",
      "launch train in GPU mode!\n",
      "INFO 2021-12-05 14:41:24,936 launch_utils.py:527] Local start 1 processes. First process distributed environment info (Only For Debug): \n",
      "    +=======================================================================================+\n",
      "    |                        Distributed Envs                      Value                    |\n",
      "    +---------------------------------------------------------------------------------------+\n",
      "    |                       PADDLE_TRAINER_ID                        0                      |\n",
      "    |                 PADDLE_CURRENT_ENDPOINT                 127.0.0.1:43889               |\n",
      "    |                     PADDLE_TRAINERS_NUM                        1                      |\n",
      "    |                PADDLE_TRAINER_ENDPOINTS                 127.0.0.1:43889               |\n",
      "    |                     PADDLE_RANK_IN_NODE                        0                      |\n",
      "    |                 PADDLE_LOCAL_DEVICE_IDS                        0                      |\n",
      "    |                 PADDLE_WORLD_DEVICE_IDS                        0                      |\n",
      "    |                     FLAGS_selected_gpus                        0                      |\n",
      "    |             FLAGS_selected_accelerators                        0                      |\n",
      "    +=======================================================================================+\n",
      "\n",
      "INFO 2021-12-05 14:41:24,936 launch_utils.py:531] details abouts PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0\n",
      "launch proc_id:899 idx:0\n",
      "[2021-12-05 14:41:26,609] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-gram-zh/ernie_gram_zh.pdparams\n",
      "W1205 14:41:26.610528   899 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1205 14:41:26.616151   899 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
      "[2021-12-05 14:41:35,748] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-gram-zh/vocab.txt\n",
      "Loaded parameters from ./checkpoints/model_3108/model_state.pdparams\n",
      "Accuracy:  0.775\n",
      "The predictions for test.txt have been saved in ./test_preds/test_5k_aug_reda_ernieGram_predictions.txt\n",
      "INFO 2021-12-05 14:41:48,981 launch.py:304] Local processes completed.\n",
      "-----------  Configuration Arguments -----------\n",
      "backend: auto\n",
      "elastic_server: None\n",
      "force: False\n",
      "gpus: 0\n",
      "heter_worker_num: None\n",
      "heter_workers: \n",
      "host: None\n",
      "http_port: None\n",
      "ips: 127.0.0.1\n",
      "job_id: None\n",
      "log_dir: log\n",
      "np: None\n",
      "nproc_per_node: None\n",
      "run_mode: None\n",
      "scale: 0\n",
      "server_num: None\n",
      "servers: \n",
      "training_script: train_pointwise.py\n",
      "training_script_args: ['--train_set_path', './train_5k_aug_reda_ngram.txt', '--dev_set_path', './dev.txt', '--epochs', '3', '--save_dir', './checkpoints', '--batch_size', '64', '--learning_rate', '2E-5']\n",
      "worker_num: None\n",
      "workers: \n",
      "------------------------------------------------\n",
      "WARNING 2021-12-05 14:41:51,316 launch.py:416] Not found distinct arguments and compiled with cuda or xpu. Default use collective mode\n",
      "launch train in GPU mode!\n",
      "INFO 2021-12-05 14:41:51,319 launch_utils.py:527] Local start 1 processes. First process distributed environment info (Only For Debug): \n",
      "    +=======================================================================================+\n",
      "    |                        Distributed Envs                      Value                    |\n",
      "    +---------------------------------------------------------------------------------------+\n",
      "    |                       PADDLE_TRAINER_ID                        0                      |\n",
      "    |                 PADDLE_CURRENT_ENDPOINT                 127.0.0.1:50860               |\n",
      "    |                     PADDLE_TRAINERS_NUM                        1                      |\n",
      "    |                PADDLE_TRAINER_ENDPOINTS                 127.0.0.1:50860               |\n",
      "    |                     PADDLE_RANK_IN_NODE                        0                      |\n",
      "    |                 PADDLE_LOCAL_DEVICE_IDS                        0                      |\n",
      "    |                 PADDLE_WORLD_DEVICE_IDS                        0                      |\n",
      "    |                     FLAGS_selected_gpus                        0                      |\n",
      "    |             FLAGS_selected_accelerators                        0                      |\n",
      "    +=======================================================================================+\n",
      "\n",
      "INFO 2021-12-05 14:41:51,319 launch_utils.py:531] details abouts PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0\n",
      "launch proc_id:963 idx:0\n",
      "[2021-12-05 14:41:53,136] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-gram-zh/ernie_gram_zh.pdparams\n",
      "W1205 14:41:53.138125   963 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1205 14:41:53.143816   963 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
      "[2021-12-05 14:42:02,250] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-gram-zh/vocab.txt\n",
      "global step 500, epoch: 1, batch: 500, loss: 0.35373, accu: 0.85700, speed: 0.10 step/s\n",
      "global step 1000, epoch: 1, batch: 1000, loss: 0.14366, accu: 0.90302, speed: 0.10 step/s\n",
      "eval dev loss: 0.66975, accu: 0.80709\n",
      "global step 1500, epoch: 2, batch: 494, loss: 0.01484, accu: 0.97514, speed: 0.09 step/s\n",
      "global step 2000, epoch: 2, batch: 994, loss: 0.08705, accu: 0.97957, speed: 0.10 step/s\n",
      "eval dev loss: 0.83987, accu: 0.81061\n",
      "global step 2500, epoch: 3, batch: 488, loss: 0.03166, accu: 0.98912, speed: 0.09 step/s\n",
      "global step 3000, epoch: 3, batch: 988, loss: 0.05743, accu: 0.99021, speed: 0.10 step/s\n",
      "eval dev loss: 0.91956, accu: 0.81425\n",
      "INFO 2021-12-05 14:52:30,940 launch.py:304] Local processes completed.\n",
      "-----------  Configuration Arguments -----------\n",
      "backend: auto\n",
      "elastic_server: None\n",
      "force: False\n",
      "gpus: 0\n",
      "heter_worker_num: None\n",
      "heter_workers: \n",
      "host: None\n",
      "http_port: None\n",
      "ips: 127.0.0.1\n",
      "job_id: None\n",
      "log_dir: log\n",
      "np: None\n",
      "nproc_per_node: None\n",
      "run_mode: None\n",
      "scale: 0\n",
      "server_num: None\n",
      "servers: \n",
      "training_script: predict_pointwise.py\n",
      "training_script_args: ['--out_dir', './test_preds/', '--train_set_suffix', '_5k_aug_reda_ngram', '--device', 'gpu', '--params_path', './checkpoints/model_3018/model_state.pdparams', '--batch_size', '64', '--max_seq_length', '128', '--input_file', 'test.txt']\n",
      "worker_num: None\n",
      "workers: \n",
      "------------------------------------------------\n",
      "WARNING 2021-12-05 14:52:32,724 launch.py:416] Not found distinct arguments and compiled with cuda or xpu. Default use collective mode\n",
      "launch train in GPU mode!\n",
      "INFO 2021-12-05 14:52:32,726 launch_utils.py:527] Local start 1 processes. First process distributed environment info (Only For Debug): \n",
      "    +=======================================================================================+\n",
      "    |                        Distributed Envs                      Value                    |\n",
      "    +---------------------------------------------------------------------------------------+\n",
      "    |                       PADDLE_TRAINER_ID                        0                      |\n",
      "    |                 PADDLE_CURRENT_ENDPOINT                 127.0.0.1:44114               |\n",
      "    |                     PADDLE_TRAINERS_NUM                        1                      |\n",
      "    |                PADDLE_TRAINER_ENDPOINTS                 127.0.0.1:44114               |\n",
      "    |                     PADDLE_RANK_IN_NODE                        0                      |\n",
      "    |                 PADDLE_LOCAL_DEVICE_IDS                        0                      |\n",
      "    |                 PADDLE_WORLD_DEVICE_IDS                        0                      |\n",
      "    |                     FLAGS_selected_gpus                        0                      |\n",
      "    |             FLAGS_selected_accelerators                        0                      |\n",
      "    +=======================================================================================+\n",
      "\n",
      "INFO 2021-12-05 14:52:32,726 launch_utils.py:531] details abouts PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0\n",
      "launch proc_id:1577 idx:0\n",
      "[2021-12-05 14:52:34,364] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-gram-zh/ernie_gram_zh.pdparams\n",
      "W1205 14:52:34.365319  1577 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1205 14:52:34.370725  1577 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
      "[2021-12-05 14:52:43,341] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-gram-zh/vocab.txt\n",
      "Loaded parameters from ./checkpoints/model_3018/model_state.pdparams\n",
      "Accuracy:  0.783\n",
      "The predictions for test.txt have been saved in ./test_preds/test_5k_aug_reda_ngram_ernieGram_predictions.txt\n",
      "INFO 2021-12-05 14:52:56,775 launch.py:304] Local processes completed.\n"
     ]
    }
   ],
   "source": [
    "run('5k', 'reda')\n",
    "run('5k', 'reda_ngram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb00df3-324a-43be-80a2-a4b05162cd54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
