{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b079a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, walk\n",
    "from os.path import isfile, join\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e8dc3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames_from_dir(file_dir, include_sub_dir=False):\n",
    "    if include_sub_dir:\n",
    "        filenames = []\n",
    "        for root, _, files in walk(file_dir, topdown=False):\n",
    "            for f in files:\n",
    "                filenames.append(join(root, f).replace(file_dir + \"/\", \"\"))\n",
    "    else:\n",
    "        filenames = [f for f in listdir(file_dir) if isfile(join(file_dir, f))]\n",
    "        \n",
    "    return filenames\n",
    "\n",
    "\n",
    "filenames = get_filenames_from_dir('../tests_pred/')\n",
    "\n",
    "\n",
    "def get_pred_labels(filepath):\n",
    "    file = open(filepath)\n",
    "    for _ in range(3):\n",
    "        next(file)\n",
    "    \n",
    "    pred, labels = [], []\n",
    "    for line in file:\n",
    "        line = line.strip().split('\\t')\n",
    "        pred.append(int(line[2]))\n",
    "        labels.append(int(line[3]))\n",
    "    \n",
    "    return pred, labels\n",
    "\n",
    "\n",
    "def PRF1(pred, labels, digits=3):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i, j in zip(pred, labels):\n",
    "        if i == 1 and j == 1:\n",
    "            tp += 1\n",
    "        elif i == 1 and j == 0:\n",
    "            fp += 1\n",
    "        elif i == 0 and j == 0:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "            \n",
    "    P = tp / (tp + fp)\n",
    "    R = tp / (tp + fn)\n",
    "    F1 = 2 * P * R / (P + R)\n",
    "    return round(P, digits), round(R, digits), round(F1, digits)\n",
    "\n",
    "\n",
    "def getBaseLinePRF1(filenames, cond):\n",
    "    for fname in filenames:\n",
    "        if 'aug' not in fname and cond in fname:\n",
    "            pred, labels = get_pred_labels('../tests_pred/' + fname)\n",
    "            yield PRF1(pred, labels, digits=3)\n",
    "            \n",
    "\n",
    "def getAugREDAPRF1(filenames, cond):\n",
    "    for fname in filenames:\n",
    "        if 'ngram' not in fname:\n",
    "            if 'reda' in fname and cond in fname:\n",
    "                pred, labels = get_pred_labels('../tests_pred/' + fname)\n",
    "                yield PRF1(pred, labels, digits=3)\n",
    "                \n",
    "                \n",
    "def getAugNgramPRF1(filenames, cond):\n",
    "    for fname in filenames:\n",
    "        if 'ngram' in fname and cond in fname:\n",
    "            pred, labels = get_pred_labels('../tests_pred/' + fname)\n",
    "            yield PRF1(pred, labels, digits=3)\n",
    "            \n",
    "\n",
    "mean = lambda x: np.round(np.mean(np.array(x), axis=0), 3)\n",
    "\n",
    "\n",
    "def report(func, filenames=filenames):\n",
    "    \n",
    "    models = ['bow', 'cnn', 'lstm', 'gru', 'ernieGram']\n",
    "    models_res = []\n",
    "    for model in models:\n",
    "        model_res = mean(list(func(filenames, model)))\n",
    "        print(f'The average Precision, Recall, and F1 for {model} is: ', model_res)\n",
    "        models_res.append(model_res)\n",
    "    print(f'The overall average Precision, Recall, and F1 is: ', mean(models_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "981ffcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average Precision, Recall, and F1 for bow is:  [0.825 0.615 0.704]\n",
      "The average Precision, Recall, and F1 for cnn is:  [0.805 0.628 0.705]\n",
      "The average Precision, Recall, and F1 for lstm is:  [0.827 0.625 0.712]\n",
      "The average Precision, Recall, and F1 for gru is:  [0.824 0.634 0.717]\n",
      "The average Precision, Recall, and F1 for ernieGram is:  [0.958 0.78  0.859]\n",
      "The overall average Precision, Recall, and F1 is:  [0.848 0.656 0.739]\n"
     ]
    }
   ],
   "source": [
    "report(getBaseLinePRF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "618bc615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average Precision, Recall, and F1 for bow is:  [0.817 0.633 0.713]\n",
      "The average Precision, Recall, and F1 for cnn is:  [0.781 0.636 0.7  ]\n",
      "The average Precision, Recall, and F1 for lstm is:  [0.814 0.634 0.713]\n",
      "The average Precision, Recall, and F1 for gru is:  [0.819 0.638 0.717]\n",
      "The average Precision, Recall, and F1 for ernieGram is:  [0.959 0.758 0.846]\n",
      "The overall average Precision, Recall, and F1 is:  [0.838 0.66  0.738]\n"
     ]
    }
   ],
   "source": [
    "report(getAugREDAPRF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee99425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average Precision, Recall, and F1 for bow is:  [0.818 0.629 0.711]\n",
      "The average Precision, Recall, and F1 for cnn is:  [0.762 0.638 0.693]\n",
      "The average Precision, Recall, and F1 for lstm is:  [0.821 0.63  0.713]\n",
      "The average Precision, Recall, and F1 for gru is:  [0.817 0.633 0.714]\n",
      "The average Precision, Recall, and F1 for ernieGram is:  [0.953 0.76  0.846]\n",
      "The overall average Precision, Recall, and F1 is:  [0.834 0.658 0.735]\n"
     ]
    }
   ],
   "source": [
    "report(getAugNgramPRF1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
